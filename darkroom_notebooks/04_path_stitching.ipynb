{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import configs\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from src.utils import find_ckpt_file, convert_to_tensor\n",
    "import h5py\n",
    "import random\n",
    "from src.envs.darkroom import DarkroomEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11-val_loss=0.942141.ckpt\n"
     ]
    }
   ],
   "source": [
    "engram_dir = \"/n/holylfs06/LABS/krajan_lab/Lab/cfang/icl-maze/\"\n",
    "wandb_project = \"darkroom_simple\"\n",
    "\n",
    "env_name = \"darkroom_dim5_corr0.0_state_dim10_envs900000_H200_explore\"\n",
    "model_name = \"transformer_end_query_embd256_layer4_head4_lr0.0001_drop0_initseed0_batch1024\"\n",
    "\n",
    "env_name = \"darkroom_dim5_corr0.0_state_dim10_envs900000_H200_explore\"\n",
    "model_name = \"transformer_end_query_embd512_layer4_head4_lr0.0001_drop0_initseed0_batch1024\"\n",
    "\n",
    "env_name = \"darkroom_dim5_corr0.25_state_dim10_envs900000_H200_explore\"\n",
    "model_name = \"transformer_end_query_embd512_layer4_head4_lr0.0001_drop0.0_initseed0_batch1024\"\n",
    "\n",
    "# env_name = \"darkroom_dim5_corr0.25_state_dim10_envs900000_H200_explore\"\n",
    "# model_name = \"transformer_end_query_embd512_layer3_head4_lr0.0001_drop0.0_initseed0_batch1024\"\n",
    "\n",
    "env_name = \"darkroom_dim5_corr0.25_state_dim10_envs1500000_H150_explore\"\n",
    "model_name = \"transformer_end_query_embd512_layer3_head4_lr0.0001_drop0.0_initseed0_batch1024\"\n",
    "\n",
    "env_name = \"darkroom_dim5_corr0.25_state_dim10_envs1500000_H150_explore\"\n",
    "model_name = \"transformer_end_query_embd512_layer3_head4_lr0.0001_drop0.0_initseed0_batch1024\"\n",
    "\n",
    "model_path = os.path.join(engram_dir, wandb_project, env_name, \"models\", model_name)\n",
    "ckpt_name = find_ckpt_file(model_path, \"best\")\n",
    "print(ckpt_name)\n",
    "path_to_pkl = os.path.join(model_path, ckpt_name)\n",
    "eval_dset_path = f\"/n/holylfs06/LABS/krajan_lab/Lab/cfang/icl-maze/{wandb_project}/{env_name}/datasets/eval.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parameters using regex\n",
    "import re\n",
    "\n",
    "n_embd = int(re.search(r'embd(\\d+)', model_name).group(1))\n",
    "n_layer = int(re.search(r'layer(\\d+)', model_name).group(1))\n",
    "n_head = int(re.search(r'head(\\d+)', model_name).group(1))\n",
    "dropout = float(re.search(r'drop(\\d*\\.?\\d*)', model_name).group(1))\n",
    "\n",
    "# Extract correlation and state_dim from eval dataset path\n",
    "state_dim = int(re.search(r'state_dim(\\d+)', eval_dset_path).group(1))\n",
    "maze_dim = int(re.search(r'_dim(\\d+)_corr', eval_dset_path).group(1))\n",
    "node_encoding_corr = float(re.search(r'corr(\\d*\\.?\\d*)', eval_dset_path).group(1))\n",
    "\n",
    "model_config = {\n",
    "    \"n_embd\": n_embd,\n",
    "    \"n_layer\": n_layer,\n",
    "    \"n_head\": n_head,\n",
    "    \"state_dim\": state_dim,\n",
    "    \"action_dim\": 5,\n",
    "    \"dropout\": dropout,\n",
    "    \"train_on_last_pred_only\": False,\n",
    "    \"test\": True,\n",
    "    \"name\": \"transformer_end_query\",\n",
    "    \"optimizer_config\": None,\n",
    "    \"linear_attention\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_306318/4170590101.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_to_pkl)\n"
     ]
    }
   ],
   "source": [
    "from src.models.transformer_end_query import Transformer\n",
    "model_config['initialization_seed'] = 0\n",
    "model = Transformer(**model_config)\n",
    "checkpoint = torch.load(path_to_pkl)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_envs = 50\n",
    "\n",
    "is_h5_file = eval_dset_path.endswith('.h5')\n",
    "if is_h5_file:\n",
    "    eval_trajs = h5py.File(eval_dset_path, 'r')\n",
    "    traj_indices = list(eval_trajs.keys())\n",
    "    n_eval_envs = min(n_eval_envs, len(traj_indices))\n",
    "    random.seed(0)\n",
    "    traj_indices = random.sample(traj_indices, n_eval_envs)\n",
    "    random.seed()\n",
    "    eval_trajs = [eval_trajs[i] for i in traj_indices]\n",
    "else:  # Pickle file\n",
    "    with open(eval_dset_path, 'rb') as f:\n",
    "        eval_trajs = pickle.load(f)\n",
    "    n_eval_envs = min(n_eval_envs, len(eval_trajs))\n",
    "    random.seed(0)\n",
    "    eval_trajs = random.sample(eval_trajs, n_eval_envs)\n",
    "    random.seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_eval = 0\n",
    "traj = eval_trajs[i_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    'maze_dim': maze_dim,\n",
    "    'horizon': 200,\n",
    "    'state_dim': state_dim,\n",
    "    'node_encoding_corr': node_encoding_corr,\n",
    "    'initialization_seed': np.array(traj['initialization_seed']).item(),\n",
    "    'goal': np.array(traj['goal'])\n",
    "}\n",
    "env = DarkroomEnv(**env_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "state_features = []\n",
    "state_features = list(env.node_map_encoding_to_pos.keys())\n",
    "\n",
    "for state_feature in state_features:\n",
    "    xs.append(env.node_map_encoding_to_pos[state_feature][0])\n",
    "    ys.append(env.node_map_encoding_to_pos[state_feature][1])\n",
    "\n",
    "reward_idx = np.argwhere([np.all(s == env.goal) for s in state_features]).item()\n",
    "xys = np.array([xs, ys]).T\n",
    "state_features = np.array(state_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xys[reward_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xys = [\n",
    "    [0,3], [1,3], [2,3], [3,3], [4,3], [4,2], [4,1], [4,0], [3,0]\n",
    "]\n",
    "\n",
    "test_xys = [\n",
    "    [0,2], [1,2], [2,2], [3,2], [4,2], [4,1], [4,0], [3,0]\n",
    "]\n",
    "\n",
    "test_xys = [\n",
    "    [0,2], [1,2], [2,2], [3,2], [4,2], [4,1], [4,0], [3,0], #forward\n",
    "    [3,0], [4,0], [4,1], [4,2], [3,2], [2,2], [1,2], [0,2] #backward\n",
    "]\n",
    "\n",
    "# test_xys = [\n",
    "#     [0,3], [1,3], [2,3], [3,3], [4,3], [4,2], [4,1], [4,0], [3,0], # forward\n",
    "#     [3,0], [4,0], [4,1], [4,2], [4,3], [3,3], [2,3], [1,3], [0,3], # backward\n",
    "#     # [0,3], [1,3], [2,3], [3,3], [4,3], [4,2], [4,1], [4,0], [3,0], # forward\n",
    "#     # [3,0], [4,0], [4,1], [4,2], [4,3], [3,3], [2,3], [1,3], [0,3], # backward\n",
    "# #       [0,3], [1,3], [2,3], [3,3], [4,3], [4,2], [4,1], [4,0], [3,0], # forward\n",
    "# #    [3,0], [4,0], [4,1], [4,2], [4,3], [3,3], [2,3], [1,3], [0,3], # backward\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onestep_action(xy1, xy2):\n",
    "    x1, y1 = xy1\n",
    "    x2, y2 = xy2\n",
    "    assert np.abs(x1-x2) + np.abs(y1-y2) <= 1\n",
    "    if xy1 == xy2:\n",
    "        return 4\n",
    "    elif x1 < x2 and y1 == y2:\n",
    "        return 2\n",
    "    elif x1 > x2 and y1 == y2:\n",
    "        return 0\n",
    "    elif x1 == x2 and y1 < y2:\n",
    "        return 1\n",
    "    elif x1 == x2 and y1 > y2:\n",
    "        return 3\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid action: {xy1} -> {xy2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_states = []\n",
    "context_actions = []\n",
    "context_next_states = []\n",
    "context_rewards = []\n",
    "query_state = []\n",
    "for i in range(len(test_xys)-1):\n",
    "    state_feature_idx = np.all(xys == test_xys[i], axis=-1)\n",
    "    next_state_feature_idx = np.all(xys == test_xys[i+1], axis=-1)\n",
    "    action_idx = get_onestep_action(test_xys[i], test_xys[i+1])\n",
    "    action = np.zeros(5)\n",
    "    action[action_idx] = 1\n",
    "    reward = 1 if np.all(test_xys[i+1] == xys[reward_idx]) else 0\n",
    "    context_states.append(state_features[state_feature_idx])\n",
    "    context_actions.append(action)\n",
    "    context_next_states.append(state_features[next_state_feature_idx])\n",
    "    context_rewards.append(reward)\n",
    "context_states = np.array(context_states).squeeze()\n",
    "context_actions = np.array(context_actions)\n",
    "context_next_states = np.array(context_next_states).squeeze()\n",
    "context_rewards = np.array(context_rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_reward = np.argwhere(traj['context_rewards']>0).squeeze()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_substitution = True\n",
    "\n",
    "if make_substitution:\n",
    "    batch = {\n",
    "        'context_states': convert_to_tensor([context_states]),\n",
    "        'context_actions': convert_to_tensor([context_actions]),\n",
    "        'context_next_states': convert_to_tensor([context_next_states]),\n",
    "        'context_rewards': convert_to_tensor([context_rewards[:, None]]),\n",
    "        }\n",
    "else:\n",
    "    batch = {\n",
    "        'context_states': convert_to_tensor([np.array(traj['context_states'])]),\n",
    "        'context_actions': convert_to_tensor([np.array(traj['context_actions'])]),\n",
    "        'context_next_states': convert_to_tensor([np.array(traj['context_next_states'])]),\n",
    "        'context_rewards': convert_to_tensor([np.array(traj['context_rewards'])[:, None]]),\n",
    "        'query_states': convert_to_tensor([np.array(traj['query_state'])]),\n",
    "        }\n",
    "    for k in batch.keys():\n",
    "        if 'context' in k:\n",
    "            batch[k] = batch[k][:, first_reward-5:first_reward+5]\n",
    "batch['zeros'] = torch.zeros(1, state_dim ** 2 + 5 + 1).float()\n",
    "for k in batch.keys():\n",
    "    if 'context' in k:\n",
    "        batch[k] = batch[k]\n",
    "    batch[k] = batch[k].to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2) to (1, 2) with action 2\n",
      "(1, 2) to (2, 2) with action 2\n",
      "(2, 2) to (3, 2) with action 2\n",
      "(3, 2) to (4, 2) with action 2\n",
      "(4, 2) to (4, 1) with action 3\n",
      "(4, 1) to (4, 0) with action 3\n",
      "(4, 0) to (3, 0) with action 0\n",
      "(3, 0) to (3, 0) with action 4\n",
      "(3, 0) to (4, 0) with action 2\n",
      "(4, 0) to (4, 1) with action 1\n",
      "(4, 1) to (4, 2) with action 1\n",
      "(4, 2) to (3, 2) with action 0\n",
      "(3, 2) to (2, 2) with action 0\n",
      "(2, 2) to (1, 2) with action 0\n",
      "(1, 2) to (0, 2) with action 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch['context_states'].shape[1]):\n",
    "    start = batch['context_states'][:, i].cpu().numpy().squeeze()\n",
    "    next = batch['context_next_states'][:, i].cpu().numpy().squeeze()\n",
    "    action = np.argmax(batch['context_actions'][:, i].cpu().numpy())\n",
    "    start = env.node_map_encoding_to_pos[tuple(start.tolist())]\n",
    "    next = env.node_map_encoding_to_pos[tuple(next.tolist())]\n",
    "    print(f'{start} to {next} with action {action}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10\n",
    "curr_xy_state = test_xys[0] #[-1] #[0]\n",
    "query_state = env.node_map_pos_to_encoding[tuple(curr_xy_state)]\n",
    "xy_path = [curr_xy_state]\n",
    "chosen_actions = []\n",
    "\n",
    "# Convert initial context tensors to numpy for easier concatenation\n",
    "context_states = batch['context_states'].cpu().numpy().squeeze()\n",
    "context_actions = batch['context_actions'].cpu().numpy().squeeze()\n",
    "context_next_states = batch['context_next_states'].cpu().numpy().squeeze()\n",
    "context_rewards = batch['context_rewards'].cpu().numpy().squeeze()\n",
    "\n",
    "for i in range(n_steps):\n",
    "    batch = {\n",
    "        'context_states': convert_to_tensor([context_states]),\n",
    "        'context_actions': convert_to_tensor([context_actions]),\n",
    "        'context_next_states': convert_to_tensor([context_next_states]),\n",
    "        'context_rewards': convert_to_tensor([context_rewards[:, None]]),\n",
    "        }\n",
    "    batch['query_states'] = convert_to_tensor([np.array(query_state)])\n",
    "    batch['query_states'] = batch['query_states'].to(model.device)\n",
    "    batch['zeros'] = torch.zeros(1, state_dim ** 2 + 5 + 1).float()\n",
    "    for k in batch.keys():\n",
    "        batch[k] = batch[k].to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(batch)\n",
    "\n",
    "    pred_action = torch.argmax(out.squeeze()).item()\n",
    "    action_encoding = np.zeros(5)\n",
    "    action_encoding[pred_action] = 1\n",
    "    next_state_encoding, reward = env.transit(np.array(query_state), action_encoding)\n",
    "\n",
    "    context_states = np.vstack([context_states, query_state])\n",
    "    context_actions = np.vstack([context_actions, action_encoding])\n",
    "    context_next_states = np.vstack([context_next_states, next_state_encoding])\n",
    "    context_rewards = np.append(context_rewards, reward)\n",
    "\n",
    "    xy_path.append(env.node_map_encoding_to_pos[tuple(next_state_encoding)])\n",
    "    chosen_actions.append(pred_action)\n",
    "    query_state = next_state_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2],\n",
       " (1, 2),\n",
       " (2, 2),\n",
       " (2, 1),\n",
       " (2, 0),\n",
       " (3, 0),\n",
       " (3, 0),\n",
       " (3, 0),\n",
       " (3, 0),\n",
       " (3, 0),\n",
       " (3, 0)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import configs\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from src.utils import find_ckpt_file, convert_to_tensor\n",
    "import h5py\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from src.envs.darkroom import DarkroomEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13-val_loss=0.911523.ckpt\n"
     ]
    }
   ],
   "source": [
    "corr = 0.25\n",
    "model_name, path_to_pkl, eval_dset_path = configs.get_model_paths(corr, \"darkroom_simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parameters using regex\n",
    "import re\n",
    "\n",
    "n_embd = int(re.search(r'embd(\\d+)', model_name).group(1))\n",
    "n_layer = int(re.search(r'layer(\\d+)', model_name).group(1))\n",
    "n_head = int(re.search(r'head(\\d+)', model_name).group(1))\n",
    "dropout = float(re.search(r'drop(\\d*\\.?\\d*)', model_name).group(1))\n",
    "\n",
    "# Extract correlation and state_dim from eval dataset path\n",
    "state_dim = int(re.search(r'state_dim(\\d+)', eval_dset_path).group(1))\n",
    "maze_dim = int(re.search(r'_dim(\\d+)_corr', eval_dset_path).group(1))\n",
    "node_encoding_corr = float(re.search(r'corr(\\d*\\.?\\d*)', eval_dset_path).group(1))\n",
    "\n",
    "model_config = {\n",
    "    \"n_embd\": n_embd,\n",
    "    \"n_layer\": n_layer,\n",
    "    \"n_head\": n_head,\n",
    "    \"state_dim\": state_dim,\n",
    "    \"action_dim\": 5,\n",
    "    \"dropout\": dropout,\n",
    "    \"test\": True,\n",
    "    \"name\": \"transformer_end_query\",\n",
    "    \"optimizer_config\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2474580/4170590101.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_to_pkl)\n"
     ]
    }
   ],
   "source": [
    "from src.models.transformer_end_query import Transformer\n",
    "model_config['initialization_seed'] = 0\n",
    "model = Transformer(**model_config)\n",
    "checkpoint = torch.load(path_to_pkl)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_envs = 100\n",
    "\n",
    "is_h5_file = eval_dset_path.endswith('.h5')\n",
    "if is_h5_file:\n",
    "    eval_trajs = h5py.File(eval_dset_path, 'r')\n",
    "    traj_indices = list(eval_trajs.keys())\n",
    "    n_eval_envs = min(n_eval_envs, len(traj_indices))\n",
    "    random.seed(0)\n",
    "    traj_indices = random.sample(traj_indices, n_eval_envs)\n",
    "    random.seed()\n",
    "    eval_trajs = [eval_trajs[i] for i in traj_indices]\n",
    "else:  # Pickle file\n",
    "    with open(eval_dset_path, 'rb') as f:\n",
    "        eval_trajs = pickle.load(f)\n",
    "    n_eval_envs = min(n_eval_envs, len(eval_trajs))\n",
    "    random.seed(0)\n",
    "    eval_trajs = random.sample(eval_trajs, n_eval_envs)\n",
    "    random.seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_env_config = {\n",
    "    'maze_dim': maze_dim,\n",
    "    'horizon': 200,\n",
    "    'state_dim': state_dim,\n",
    "    'node_encoding_corr': node_encoding_corr,\n",
    "    'initialization_seed': None, # will be overwritten\n",
    "    'goal': None # will be overwritten\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define test goals and trajectories in XY space\n",
    "Goal location and long-path trajectories will be overwritten in each test environment, so that we can aggregate performance in an automated way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [3 0]]\n"
     ]
    }
   ],
   "source": [
    "test_xy_goals = []\n",
    "for i_eval in range(n_eval_envs):\n",
    "    traj = eval_trajs[i_eval]\n",
    "    base_env_config['initialization_seed'] = np.array(traj['initialization_seed']).item()\n",
    "    base_env_config['goal'] = np.array(traj['goal'])\n",
    "    env = DarkroomEnv(**base_env_config)\n",
    "    xy_goal = env.node_map_encoding_to_pos[tuple(env.goal.tolist())]\n",
    "    test_xy_goals.append(xy_goal)\n",
    "\n",
    "print(np.unique(test_xy_goals, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xy_goals = np.unique(test_xy_goals, axis=0)\n",
    "test_xy_trajectories = [\n",
    "    [[0,0], [0,1], [1,1], [2,1], [3,1], [4,1], [4,2], [3,2], [2,2]],\n",
    "    [[0,3], [1,3], [2,3], [3,3], [4,3], [4,2], [4,1], [4,0], [3,0]]\n",
    "]\n",
    "test_dist_from_goal = [4, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onestep_action(xy1, xy2):\n",
    "    x1, y1 = xy1\n",
    "    x2, y2 = xy2\n",
    "    assert np.abs(x1-x2) + np.abs(y1-y2) <= 1\n",
    "    if xy1 == xy2:\n",
    "        return 4\n",
    "    elif x1 < x2 and y1 == y2:\n",
    "        return 2\n",
    "    elif x1 > x2 and y1 == y2:\n",
    "        return 0\n",
    "    elif x1 == x2 and y1 < y2:\n",
    "        return 1\n",
    "    elif x1 == x2 and y1 > y2:\n",
    "        return 3\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid action: {xy1} -> {xy2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trajectory_batch(xy_trajectory, xy_goal, env):\n",
    "    context_states = []\n",
    "    context_actions = []\n",
    "    context_next_states = []\n",
    "    context_rewards = []\n",
    "    query_state = []\n",
    "    for i in range(len(xy_trajectory)-1):\n",
    "        state_feature = np.array(env.node_map_pos_to_encoding[tuple(xy_trajectory[i])])\n",
    "        next_state_feature = np.array(env.node_map_pos_to_encoding[tuple(xy_trajectory[i+1])])\n",
    "        action_idx = get_onestep_action(xy_trajectory[i], xy_trajectory[i+1])\n",
    "        action = np.zeros(5)\n",
    "        action[action_idx] = 1\n",
    "        reward = 1 if np.all(xy_trajectory[i+1] == xy_goal) else 0\n",
    "        context_states.append(state_feature)\n",
    "        context_actions.append(action)\n",
    "        context_next_states.append(next_state_feature)\n",
    "        context_rewards.append(reward)\n",
    "    context_states = np.array(context_states).squeeze()\n",
    "    context_actions = np.array(context_actions)\n",
    "    context_next_states = np.array(context_next_states).squeeze()\n",
    "    context_rewards = np.array(context_rewards)\n",
    "    batch = {\n",
    "        'context_states': convert_to_tensor([context_states]),\n",
    "        'context_actions': convert_to_tensor([context_actions]),\n",
    "        'context_next_states': convert_to_tensor([context_next_states]),\n",
    "        'context_rewards': convert_to_tensor([context_rewards[:, None]]),\n",
    "    }\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'test_idx': [],\n",
    "    'i_eval': [],\n",
    "    'success': [],\n",
    "}\n",
    "\n",
    "for test_idx in range(len(test_xy_goals)):\n",
    "    test_xy_goal = test_xy_goals[test_idx]\n",
    "    test_xy_trajectory = test_xy_trajectories[test_idx]\n",
    "    dist_from_goal = test_dist_from_goal[test_idx]\n",
    "\n",
    "    repeats = 1\n",
    "    full_test_xy_trajectory = []\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        full_test_xy_trajectory.extend(deepcopy(test_xy_trajectory))\n",
    "        full_test_xy_trajectory.extend(deepcopy(test_xy_trajectory[:-1][::-1]))\n",
    "\n",
    "    for i_eval in range(n_eval_envs):\n",
    "        traj = eval_trajs[i_eval]\n",
    "        base_env_config['initialization_seed'] = np.array(traj['initialization_seed']).item()\n",
    "        base_env_config['goal'] = np.array(traj['goal'])\n",
    "        env = DarkroomEnv(**base_env_config)\n",
    "        env.goal = np.array(env.node_map_pos_to_encoding[tuple(test_xy_goal)])\n",
    "\n",
    "        batch = generate_trajectory_batch(full_test_xy_trajectory, test_xy_goal, env)\n",
    "\n",
    "        n_steps = dist_from_goal\n",
    "        curr_xy_state = full_test_xy_trajectory[-1]\n",
    "        query_state = env.node_map_pos_to_encoding[tuple(curr_xy_state)]\n",
    "        returns = 0\n",
    "        \n",
    "        # Convert initial context tensors to numpy for easier concatenation\n",
    "        context_states = batch['context_states'].cpu().numpy().squeeze()\n",
    "        context_actions = batch['context_actions'].cpu().numpy().squeeze()\n",
    "        context_next_states = batch['context_next_states'].cpu().numpy().squeeze()\n",
    "        context_rewards = batch['context_rewards'].cpu().numpy().squeeze()\n",
    "        \n",
    "        for i in range(n_steps):\n",
    "            batch = {\n",
    "                'context_states': convert_to_tensor([context_states]),\n",
    "                'context_actions': convert_to_tensor([context_actions]),\n",
    "                'context_next_states': convert_to_tensor([context_next_states]),\n",
    "                'context_rewards': convert_to_tensor([context_rewards[:, None]]),\n",
    "                }\n",
    "            batch['query_states'] = convert_to_tensor([np.array(query_state)])\n",
    "            batch['query_states'] = batch['query_states'].to(model.device)\n",
    "            batch['zeros'] = torch.zeros(1, state_dim ** 2 + 5 + 1).float()\n",
    "            for k in batch.keys():\n",
    "                batch[k] = batch[k].to(model.device)\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                out = model(batch)\n",
    "        \n",
    "            pred_action = torch.argmax(out.squeeze()).item()\n",
    "            action_encoding = np.zeros(5)\n",
    "            action_encoding[pred_action] = 1\n",
    "            next_state_encoding, reward = env.transit(np.array(query_state), action_encoding)\n",
    "        \n",
    "            context_states = np.vstack([context_states, query_state])\n",
    "            context_actions = np.vstack([context_actions, action_encoding])\n",
    "            context_next_states = np.vstack([context_next_states, next_state_encoding])\n",
    "            context_rewards = np.append(context_rewards, reward)\n",
    "            query_state = next_state_encoding\n",
    "            returns += reward\n",
    "\n",
    "        results['test_idx'].append(test_idx)\n",
    "        results['i_eval'].append(i_eval)\n",
    "        results['success'].append(returns > 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x175 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "fig, ax = plt.subplots(figsize=(1., 1.75))\n",
    "sns.barplot(data=df, x='test_idx', y='success')\n",
    "plt.ylabel('Shortcut Success Rate', fontsize=8)\n",
    "plt.xlabel('Eval Test', fontsize=8)\n",
    "plt.xticks([0, 1], [1, 2], fontsize=6)\n",
    "plt.yticks([0, 0.25, 0.5, 0.75], [0, '', 0.5, ''], fontsize=6)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs_app/D_13c.png', transparent=True, dpi=300)\n",
    "plt.savefig('figs_app/D_13c.pdf', transparent=True, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016000000000000003\n",
      "6.400000000000002e-05\n"
     ]
    }
   ],
   "source": [
    "print((1/env.action_dim)**4)\n",
    "print((1/env.action_dim)**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

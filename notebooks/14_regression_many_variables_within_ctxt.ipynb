{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import configs\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "from src.utils import find_ckpt_file, convert_to_tensor\n",
    "import h5py\n",
    "import random\n",
    "from src.evals.eval_trees import EvalTrees\n",
    "from src.evals.eval_trees import EvalCntrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=31-val_loss=0.000400.ckpt\n"
     ]
    }
   ],
   "source": [
    "engram_dir = \"/n/holylfs06/LABS/krajan_lab/Lab/cfang/icl-maze/\"\n",
    "wandb_project = \"tree_maze\"\n",
    "env_name = f\"cntree_layers7_bprob0.9_corr{corr}_state_dim10_envs300000_H800_explore\"\n",
    "if corr == 0.25:\n",
    "    model_name = \"transformer_end_query_embd512_layer3_head4_lr0.0001_drop0.2_initseed0_batch512\"\n",
    "elif corr == 0.:\n",
    "    model_name = \"transformer_end_query_embd512_layer3_head4_lr1e-05_drop0_initseed1_batch256\"\n",
    "else:\n",
    "    raise ValueError(f\"Unknown correlation value: {corr}\")\n",
    "model_path = os.path.join(engram_dir, wandb_project, env_name, \"models\", model_name)\n",
    "ckpt_name = find_ckpt_file(model_path, \"best\")\n",
    "print(ckpt_name)\n",
    "path_to_pkl = os.path.join(model_path, ckpt_name)\n",
    "\n",
    "eval_dset_path = f\"/n/holylfs06/LABS/krajan_lab/Lab/cfang/icl-maze/cntree/cntree_layers7_bprob1.0_corr{corr}_state_dim10_envs1000_H1600_explore/datasets/eval.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parameters using regex\n",
    "import re\n",
    "\n",
    "n_embd = int(re.search(r'embd(\\d+)', model_name).group(1))\n",
    "n_layer = int(re.search(r'layer(\\d+)', model_name).group(1))\n",
    "n_head = int(re.search(r'head(\\d+)', model_name).group(1))\n",
    "dropout = float(re.search(r'drop(\\d*\\.?\\d*)', model_name).group(1))\n",
    "\n",
    "# Extract correlation and state_dim from eval dataset path\n",
    "state_dim = int(re.search(r'state_dim(\\d+)', eval_dset_path).group(1))\n",
    "\n",
    "model_config = {\n",
    "    \"n_embd\": n_embd,\n",
    "    \"n_layer\": n_layer,\n",
    "    \"n_head\": n_head,\n",
    "    \"state_dim\": 10,\n",
    "    \"action_dim\": 4,\n",
    "    \"dropout\": dropout,\n",
    "    \"train_on_last_pred_only\": False,\n",
    "    \"test\": True,\n",
    "    \"name\": \"transformer_end_query\",\n",
    "    \"optimizer_config\": None,\n",
    "    \"linear_attention\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2699809/4170590101.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_to_pkl)\n"
     ]
    }
   ],
   "source": [
    "from src.models.transformer_end_query import Transformer\n",
    "model_config['initialization_seed'] = 0\n",
    "model = Transformer(**model_config)\n",
    "checkpoint = torch.load(path_to_pkl)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_envs = -1 #50\n",
    "\n",
    "is_h5_file = eval_dset_path.endswith('.h5')\n",
    "if is_h5_file:\n",
    "    eval_trajs = h5py.File(eval_dset_path, 'r')\n",
    "    traj_indices = list(eval_trajs.keys())\n",
    "    n_eval_envs = min(n_eval_envs, len(traj_indices))\n",
    "    random.seed(0)\n",
    "    traj_indices = random.sample(traj_indices, n_eval_envs)\n",
    "    random.seed()\n",
    "    if n_eval_envs != -1:\n",
    "        eval_trajs = [eval_trajs[i] for i in traj_indices]\n",
    "    else:\n",
    "        n_eval_envs = len(traj_indices)\n",
    "else:  # Pickle file\n",
    "    with open(eval_dset_path, 'rb') as f:\n",
    "        eval_trajs = pickle.load(f)\n",
    "    n_eval_envs = min(n_eval_envs, len(eval_trajs))\n",
    "    if n_eval_envs != -1:\n",
    "        random.seed(0)\n",
    "        eval_trajs = random.sample(eval_trajs, n_eval_envs)\n",
    "        random.seed()\n",
    "    else:\n",
    "        n_eval_envs = len(eval_trajs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(traj, model, state_features, seq_length, zero_reward=False):\n",
    "    hidden_states = [[] for _ in range(model.n_layer)]\n",
    "    outputs = []\n",
    "    \n",
    "    for state_feature in state_features: \n",
    "        batch = {\n",
    "            'context_states': convert_to_tensor([np.array(traj['context_states'])]),\n",
    "            'context_actions': convert_to_tensor([np.array(traj['context_actions'])]),\n",
    "            'context_next_states': convert_to_tensor([np.array(traj['context_next_states'])]),\n",
    "            'context_rewards': convert_to_tensor([np.array(traj['context_rewards'])[:, None]]),\n",
    "            'query_states': convert_to_tensor([np.array(state_feature)]),\n",
    "            }\n",
    "        batch['zeros'] = torch.zeros(1, 10 ** 2 + 4 + 1).float()\n",
    "        for k in batch.keys():\n",
    "            if 'context' in k:\n",
    "                batch[k] = batch[k][:,:seq_length]\n",
    "            batch[k] = batch[k].to(model.device)\n",
    "        model.save_activations = True\n",
    "        if zero_reward:\n",
    "            batch['context_rewards'] *= 0\n",
    "        with torch.no_grad():\n",
    "            out = model(batch)\n",
    "            outputs.append(torch.argmax(out).item())\n",
    "        _hidden_states = model.activations['hidden_states'][1:] # Tuple over layers\n",
    "        for i_layer in range(model.n_layer):\n",
    "            hidden_states[i_layer].append(_hidden_states[i_layer])\n",
    "    return hidden_states, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Across context decoding\n",
    "(within-context is not that good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtree_location(layer, pos, subtree):\n",
    "    midpt = 2**(layer-1)\n",
    "    quarter_pt = midpt//2\n",
    "    eighth_pt = quarter_pt//2\n",
    "    if layer == 0:\n",
    "        return 0\n",
    "    if subtree == 'half':\n",
    "        return 1 if pos < midpt else 2\n",
    "    elif subtree == 'quarter':\n",
    "        if layer == 1:\n",
    "            return 0\n",
    "        bins = np.arange(0, 2**layer, quarter_pt)\n",
    "        return np.digitize([pos], bins)[0]\n",
    "    elif subtree == 'eighth':\n",
    "        if (layer == 1) or (layer == 2):\n",
    "            return 0\n",
    "        bins = np.arange(0, 2**layer, eighth_pt)\n",
    "        return np.digitize([pos], bins)[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_matrices(i_eval):\n",
    "    X = [[] for _ in range(model.n_layer)]\n",
    "    Ys_dict = {\n",
    "        \"dist_from_goal\": [],\n",
    "        \"layer\": [],\n",
    "        \"node_identity\": [],\n",
    "        \"maze_half\": [],\n",
    "        \"maze_quarter\": [],\n",
    "        \"maze_eighth\": [],\n",
    "        'is_goal': [],\n",
    "        'same_half_as_goal': [],\n",
    "        'same_quarter_as_goal': [],\n",
    "        'opt_action': [],\n",
    "        'state_feature': [],\n",
    "    }\n",
    "    \n",
    "    traj = eval_trajs[i_eval]\n",
    "    seen_states = np.vstack((traj['context_states'][:1], traj['context_next_states']))\n",
    "    seen_states = np.unique(seen_states, axis=0) \n",
    "\n",
    "    first_reward = np.argwhere(np.array(traj['context_rewards'])>0)\n",
    "    if (first_reward.size == 0) or (first_reward[0] > 800):\n",
    "        return None, None, None\n",
    "\n",
    "    env_config = {\n",
    "        'max_layers': 7,\n",
    "        'horizon': 1600,\n",
    "        'branching_prob': 1.0,\n",
    "        'node_encoding_corr': corr,\n",
    "        'state_dim': state_dim,\n",
    "        'initialization_seed': np.array(traj['initialization_seed']).item()\n",
    "    }\n",
    "    env = EvalCntrees().create_env(env_config, np.array(traj['goal']), i_eval)\n",
    "    opt_action_map, dist_from_goal = env.make_opt_action_dict()\n",
    "\n",
    "    seq_length = 1000\n",
    "    hidden_states, outputs = run_model(traj, model, seen_states, seq_length)\n",
    "    goal_node = env.node_map[tuple(env.goal.tolist())]\n",
    "    goal_layer = goal_node.layer\n",
    "    goal_pos = goal_node.pos\n",
    "    for state_idx, state_feature in enumerate(seen_states):\n",
    "        state_feature_tuple = tuple(state_feature.tolist())\n",
    "        d = dist_from_goal[state_feature_tuple]\n",
    "        layer = env.node_map[state_feature_tuple].layer\n",
    "        pos = env.node_map[state_feature_tuple].pos\n",
    "        node_identity = 2**layer + pos\n",
    "        maze_half = get_subtree_location(layer, pos, 'half')\n",
    "        maze_quarter = get_subtree_location(layer, pos, 'quarter')\n",
    "        maze_eighth = get_subtree_location(layer, pos, 'eighth')\n",
    "        action = outputs[state_idx]\n",
    "        opt_action = np.zeros(4)\n",
    "        opt_action[opt_action_map[state_feature_tuple]] = 1\n",
    "        \n",
    "        Ys_dict[\"dist_from_goal\"].append(d)\n",
    "        Ys_dict[\"layer\"].append(layer)\n",
    "        Ys_dict[\"node_identity\"].append(node_identity)\n",
    "        Ys_dict[\"maze_half\"].append(maze_half)\n",
    "        Ys_dict[\"maze_quarter\"].append(maze_quarter)\n",
    "        Ys_dict[\"maze_eighth\"].append(maze_eighth)\n",
    "        Ys_dict[\"is_goal\"].append(state_feature_tuple == tuple(env.goal.tolist()))\n",
    "        Ys_dict[\"same_half_as_goal\"].append(maze_half == get_subtree_location(goal_layer, goal_pos, 'half'))\n",
    "        Ys_dict[\"same_quarter_as_goal\"].append(maze_quarter == get_subtree_location(goal_layer, goal_pos, 'quarter'))\n",
    "        Ys_dict[\"opt_action\"].append(opt_action_map[state_feature_tuple])\n",
    "        Ys_dict[\"state_feature\"].append(state_feature)\n",
    "\n",
    "        for layer in range(model.n_layer):\n",
    "            hidden_state = hidden_states[layer][state_idx][0, -1].to('cpu').numpy()\n",
    "            X[layer].append(hidden_state)\n",
    "    torch.cuda.empty_cache()\n",
    "    test_size = 0.1\n",
    "    test_start_idx = int(len(X[0])*(1-test_size))\n",
    "    all_indices = np.arange(len(X[0]))\n",
    "    np.random.shuffle(all_indices)\n",
    "    train_indices = all_indices[:test_start_idx]\n",
    "    test_indices = all_indices[test_start_idx:]\n",
    "\n",
    "    X_train = [[] for _ in range(model.n_layer)]\n",
    "    X_test = [[] for _ in range(model.n_layer)]\n",
    "    Ys_dict_train_test = {key: {'Y_train': [], 'Y_test': []} for key in Ys_dict}\n",
    "    # Use same indices for all layers to keep corresponding samples together\n",
    "    for layer, layer_data in enumerate(X):\n",
    "        X_train[layer] = [layer_data[i] for i in train_indices]\n",
    "        X_test[layer] = [layer_data[i] for i in test_indices]\n",
    "    for key in Ys_dict:\n",
    "        Ys_dict_train_test[key]['Y_train'] = [Ys_dict[key][i] for i in train_indices]\n",
    "        Ys_dict_train_test[key]['Y_test'] = [Ys_dict[key][i] for i in test_indices]\n",
    "    return X_train, X_test, Ys_dict_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def fit_and_evaluate_regression(X_train, Y_train, X_test, Y_test, print_scores=True):\n",
    "    from joblib import Parallel, delayed\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.linear_model import Ridge\n",
    "    \n",
    "    X_train_np = [np.array([_x for _x in x]) for x in X_train]\n",
    "    X_test_np = [np.array([_x for _x in x]) for x in X_test]\n",
    "    Y_train_np = np.array(Y_train)\n",
    "    Y_test_np = np.array(Y_test)\n",
    "\n",
    "    alphas = np.logspace(0, 4, 10)\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    def evaluate_fold(X, y, train_idx, val_idx, alpha):\n",
    "        # Train on this fold\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('ridge', Ridge(alpha=alpha))\n",
    "        ])\n",
    "        pipeline.fit(X[train_idx], y[train_idx])\n",
    "        # Get validation score\n",
    "        val_score = pipeline.score(X[val_idx], y[val_idx])\n",
    "        return val_score\n",
    "\n",
    "    pipelines = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for layer in range(len(X_train)):\n",
    "        # Parallel CV for each alpha\n",
    "        cv_scores = {alpha: [] for alpha in alphas}\n",
    "        for alpha in alphas:\n",
    "            scores = Parallel(n_jobs=-1)(\n",
    "                delayed(evaluate_fold)(\n",
    "                    X_train_np[layer], Y_train_np, \n",
    "                    train_idx, val_idx, alpha\n",
    "                )\n",
    "                for train_idx, val_idx in kf.split(X_train_np[layer])\n",
    "            )\n",
    "            cv_scores[alpha] = np.mean(scores)\n",
    "        \n",
    "        # Find best alpha\n",
    "        best_alpha = max(cv_scores.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Train final model with best alpha\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('ridge', Ridge(alpha=best_alpha))\n",
    "        ])\n",
    "        pipeline.fit(X_train_np[layer], Y_train_np)\n",
    "        \n",
    "        train_score = pipeline.score(X_train_np[layer], Y_train_np)\n",
    "        test_score = pipeline.score(X_test_np[layer], Y_test_np)\n",
    "        \n",
    "        pipelines.append(pipeline)\n",
    "        test_scores.append(test_score)\n",
    "        \n",
    "        if print_scores:\n",
    "            print(f\"Layer {layer}:\")\n",
    "            print(f\"Best alpha: {best_alpha:.3f}\")\n",
    "            print(f\"Train R2: {train_score:.3f}\")\n",
    "            print(f\"Test R2: {test_score:.3f}\")\n",
    "            print()\n",
    "            \n",
    "    return pipelines, test_scores\n",
    "\n",
    "def fit_and_evaluate_classification(X_train, Y_train, X_test, Y_test, print_scores=True):\n",
    "    import warnings\n",
    "    from sklearn.exceptions import ConvergenceWarning\n",
    "    warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    from joblib import Parallel, delayed\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "    X_train_np = [np.array([_x for _x in x]) for x in X_train]\n",
    "    X_test_np = [np.array([_x for _x in x]) for x in X_test]\n",
    "    Y_train_np = np.array(Y_train)\n",
    "    Y_test_np = np.array(Y_test)\n",
    "\n",
    "    Cs = np.logspace(-4, 4, 10)\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    def evaluate_fold(X, y, train_idx, val_idx, C):\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LogisticRegression(\n",
    "                C=C, \n",
    "                max_iter=3000,\n",
    "                class_weight='balanced',  # Add class weighting\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        pipeline.fit(X[train_idx], y[train_idx])\n",
    "        y_val_pred = pipeline.predict(X[val_idx])\n",
    "        # Use balanced accuracy score instead of regular accuracy\n",
    "        return balanced_accuracy_score(y[val_idx], y_val_pred)\n",
    "\n",
    "    pipelines = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for layer in range(len(X_train)):\n",
    "        # Parallel CV for each C value\n",
    "        cv_scores = {C: [] for C in Cs}\n",
    "        for C in Cs:\n",
    "            scores = Parallel(n_jobs=-1)(\n",
    "                delayed(evaluate_fold)(\n",
    "                    X_train_np[layer], Y_train_np, \n",
    "                    train_idx, val_idx, C\n",
    "                )\n",
    "                for train_idx, val_idx in kf.split(X_train_np[layer])\n",
    "            )\n",
    "            cv_scores[C] = np.mean(scores)\n",
    "        \n",
    "        # Find best C\n",
    "        best_C = max(cv_scores.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Train final model with best C\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LogisticRegression(\n",
    "                C=best_C, \n",
    "                max_iter=3000,\n",
    "                class_weight='balanced',  # Add class weighting\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        pipeline.fit(X_train_np[layer], Y_train_np)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(X_train_np[layer])\n",
    "        y_test_pred = pipeline.predict(X_test_np[layer])\n",
    "        \n",
    "        # Use balanced metrics\n",
    "        train_accuracy = balanced_accuracy_score(Y_train_np, y_train_pred)\n",
    "        test_accuracy = balanced_accuracy_score(Y_test_np, y_test_pred)\n",
    "        train_f1 = f1_score(Y_train_np, y_train_pred, average='weighted')\n",
    "        test_f1 = f1_score(Y_test_np, y_test_pred, average='weighted')\n",
    "\n",
    "        if print_scores:\n",
    "            print(f\"Layer {layer}:\")\n",
    "            print(f\"Best C: {best_C:.3f}\")\n",
    "            print(f\"Train Balanced Accuracy: {train_accuracy:.3f}\")\n",
    "            print(f\"Test Balanced Accuracy: {test_accuracy:.3f}\")\n",
    "            print(f\"Train Weighted F1: {train_f1:.3f}\")\n",
    "            print(f\"Test Weighted F1: {test_f1:.3f}\")\n",
    "            # Add class distribution information\n",
    "            print(\"Class distribution:\")\n",
    "            for cls in np.unique(Y_train_np):\n",
    "                print(f\"Class {cls}: {np.sum(Y_train_np == cls)} samples\")\n",
    "            print()\n",
    "\n",
    "    return pipelines, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`GPT2SdpaAttention` is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Ys_dict = make_train_test_matrices(i_eval=3)\n",
    "if X_train is None:\n",
    "    print(\"No data for this environment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.046\n",
      "Train Balanced Accuracy: 0.977\n",
      "Test Balanced Accuracy: 0.938\n",
      "Train Weighted F1: 0.968\n",
      "Test Weighted F1: 0.913\n",
      "Class distribution:\n",
      "Class False: 64 samples\n",
      "Class True: 28 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.046\n",
      "Train Balanced Accuracy: 0.959\n",
      "Test Balanced Accuracy: 0.771\n",
      "Train Weighted F1: 0.957\n",
      "Test Weighted F1: 0.818\n",
      "Class distribution:\n",
      "Class False: 64 samples\n",
      "Class True: 28 samples\n",
      "\n",
      "Layer 2:\n",
      "Best C: 2.783\n",
      "Train Balanced Accuracy: 1.000\n",
      "Test Balanced Accuracy: 0.667\n",
      "Train Weighted F1: 1.000\n",
      "Test Weighted F1: 0.783\n",
      "Class distribution:\n",
      "Class False: 64 samples\n",
      "Class True: 28 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"same_quarter_as_goal\"][\"Y_train\"], X_test, Ys_dict[\"same_quarter_as_goal\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home04/cfang/.conda/envs/jax/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.001\n",
      "Train Balanced Accuracy: 0.775\n",
      "Test Balanced Accuracy: 0.720\n",
      "Train Weighted F1: 0.868\n",
      "Test Weighted F1: 0.854\n",
      "Class distribution:\n",
      "Class False: 5718 samples\n",
      "Class True: 324 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.006\n",
      "Train Balanced Accuracy: 0.899\n",
      "Test Balanced Accuracy: 0.864\n",
      "Train Weighted F1: 0.936\n",
      "Test Weighted F1: 0.926\n",
      "Class distribution:\n",
      "Class False: 5718 samples\n",
      "Class True: 324 samples\n",
      "\n",
      "Layer 2:\n",
      "Best C: 0.006\n",
      "Train Balanced Accuracy: 0.918\n",
      "Test Balanced Accuracy: 0.901\n",
      "Train Weighted F1: 0.949\n",
      "Test Weighted F1: 0.938\n",
      "Class distribution:\n",
      "Class False: 5718 samples\n",
      "Class True: 324 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(\n",
    "    X_train,\n",
    "    [y <= 3 for y in Ys_dict[\"dist_from_goal\"][\"Y_train\"]],\n",
    "    X_test,\n",
    "    [y <= 3 for y in Ys_dict[\"dist_from_goal\"][\"Y_test\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best alpha: 464.159\n",
      "Train R2: 0.313\n",
      "Test R2: 0.283\n",
      "\n",
      "Layer 1:\n",
      "Best alpha: 166.810\n",
      "Train R2: 0.435\n",
      "Test R2: 0.383\n",
      "\n",
      "Layer 2:\n",
      "Best alpha: 166.810\n",
      "Train R2: 0.469\n",
      "Test R2: 0.366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_regression(X_train, Ys_dict[\"dist_from_goal\"][\"Y_train\"], X_test, Ys_dict[\"dist_from_goal\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.000\n",
      "Train Balanced Accuracy: 0.817\n",
      "Test Balanced Accuracy: 0.761\n",
      "Train Weighted F1: 0.797\n",
      "Test Weighted F1: 0.783\n",
      "Class distribution:\n",
      "Class False: 5710 samples\n",
      "Class True: 332 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.001\n",
      "Train Balanced Accuracy: 0.951\n",
      "Test Balanced Accuracy: 0.920\n",
      "Train Weighted F1: 0.937\n",
      "Test Weighted F1: 0.914\n",
      "Class distribution:\n",
      "Class False: 5710 samples\n",
      "Class True: 332 samples\n",
      "\n",
      "Layer 2:\n",
      "Best C: 0.000\n",
      "Train Balanced Accuracy: 0.983\n",
      "Test Balanced Accuracy: 0.983\n",
      "Train Weighted F1: 0.983\n",
      "Test Weighted F1: 0.971\n",
      "Class distribution:\n",
      "Class False: 5710 samples\n",
      "Class True: 332 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_Y_train = [a in [1, 2] for a in Ys_dict['opt_action'][\"Y_train\"]]\n",
    "_Y_test = [a in [1, 2] for a in Ys_dict['opt_action'][\"Y_test\"]]\n",
    "pipeline, test_score = fit_and_evaluate_classification(\n",
    "    X_train, _Y_train, X_test, _Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.001\n",
      "Train Balanced Accuracy: 0.618\n",
      "Test Balanced Accuracy: 0.606\n",
      "Train Weighted F1: 0.636\n",
      "Test Weighted F1: 0.628\n",
      "Class distribution:\n",
      "Class False: 5088 samples\n",
      "Class True: 1768 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.046\n",
      "Train Balanced Accuracy: 0.705\n",
      "Test Balanced Accuracy: 0.645\n",
      "Train Weighted F1: 0.729\n",
      "Test Weighted F1: 0.653\n",
      "Class distribution:\n",
      "Class False: 5088 samples\n",
      "Class True: 1768 samples\n",
      "\n",
      "Layer 2:\n",
      "Best C: 0.046\n",
      "Train Balanced Accuracy: 0.730\n",
      "Test Balanced Accuracy: 0.645\n",
      "Train Weighted F1: 0.748\n",
      "Test Weighted F1: 0.677\n",
      "Class distribution:\n",
      "Class False: 5088 samples\n",
      "Class True: 1768 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(\n",
    "    X_train, Ys_dict[\"same_quarter_as_goal\"][\"Y_train\"], X_test, Ys_dict[\"same_quarter_as_goal\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home04/cfang/.conda/envs/jax/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/n/home04/cfang/.conda/envs/jax/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/n/home04/cfang/.conda/envs/jax/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.006\n",
      "Train Balanced Accuracy: 0.551\n",
      "Test Balanced Accuracy: 0.419\n",
      "Train Weighted F1: 0.594\n",
      "Test Weighted F1: 0.572\n",
      "Class distribution:\n",
      "Class 0: 63 samples\n",
      "Class 1: 126 samples\n",
      "Class 2: 250 samples\n",
      "Class 3: 484 samples\n",
      "Class 4: 925 samples\n",
      "Class 5: 1745 samples\n",
      "Class 6: 3263 samples\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home04/cfang/.conda/envs/jax/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/n/home04/cfang/.conda/envs/jax/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/n/home04/cfang/.conda/envs/jax/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/n/home04/cfang/.conda/envs/jax/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/n/home04/cfang/.conda/envs/jax/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/n/home04/cfang/.conda/envs/jax/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/n/home04/cfang/.conda/envs/jax/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1:\n",
      "Best C: 0.000\n",
      "Train Balanced Accuracy: 0.653\n",
      "Test Balanced Accuracy: 0.606\n",
      "Train Weighted F1: 0.735\n",
      "Test Weighted F1: 0.722\n",
      "Class distribution:\n",
      "Class 0: 63 samples\n",
      "Class 1: 126 samples\n",
      "Class 2: 250 samples\n",
      "Class 3: 484 samples\n",
      "Class 4: 925 samples\n",
      "Class 5: 1745 samples\n",
      "Class 6: 3263 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"layer\"][\"Y_train\"], X_test, Ys_dict[\"layer\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.001\n",
      "Train Accuracy: 0.068\n",
      "Test Accuracy: 0.024\n",
      "Train F1: 0.058\n",
      "Test F1: 0.022\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.046\n",
      "Train Accuracy: 0.267\n",
      "Test Accuracy: 0.047\n",
      "Train F1: 0.260\n",
      "Test F1: 0.039\n",
      "\n",
      "Layer 2:\n",
      "Best C: 0.359\n",
      "Train Accuracy: 0.590\n",
      "Test Accuracy: 0.051\n",
      "Train F1: 0.582\n",
      "Test F1: 0.041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"node_identity\"][\"Y_train\"], X_test, Ys_dict[\"node_identity\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.359\n",
      "Train Accuracy: 0.629\n",
      "Test Accuracy: 0.477\n",
      "Train F1: 0.750\n",
      "Test F1: 0.622\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.046\n",
      "Train Accuracy: 0.658\n",
      "Test Accuracy: 0.508\n",
      "Train F1: 0.767\n",
      "Test F1: 0.639\n",
      "\n",
      "Layer 2:\n",
      "Best C: 0.000\n",
      "Train Accuracy: 0.575\n",
      "Test Accuracy: 0.476\n",
      "Train F1: 0.686\n",
      "Test F1: 0.622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"maze_half\"][\"Y_train\"], X_test, Ys_dict[\"maze_half\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 2.783\n",
      "Train Accuracy: 0.460\n",
      "Test Accuracy: 0.240\n",
      "Train F1: 0.502\n",
      "Test F1: 0.267\n",
      "\n",
      "Layer 1:\n",
      "Best C: 2.783\n",
      "Train Accuracy: 0.508\n",
      "Test Accuracy: 0.264\n",
      "Train F1: 0.595\n",
      "Test F1: 0.323\n",
      "\n",
      "Layer 2:\n",
      "Best C: 0.359\n",
      "Train Accuracy: 0.508\n",
      "Test Accuracy: 0.264\n",
      "Train F1: 0.593\n",
      "Test F1: 0.331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"maze_quarter\"][\"Y_train\"], X_test, Ys_dict[\"maze_quarter\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.001\n",
      "Train Accuracy: 0.202\n",
      "Test Accuracy: 0.116\n",
      "Train F1: 0.201\n",
      "Test F1: 0.121\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.006\n",
      "Train Accuracy: 0.292\n",
      "Test Accuracy: 0.137\n",
      "Train F1: 0.298\n",
      "Test F1: 0.142\n",
      "\n",
      "Layer 2:\n",
      "Best C: 0.001\n",
      "Train Accuracy: 0.247\n",
      "Test Accuracy: 0.133\n",
      "Train F1: 0.257\n",
      "Test F1: 0.151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"maze_eighth\"][\"Y_train\"], X_test, Ys_dict[\"maze_eighth\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.006\n",
      "Train Accuracy: 0.958\n",
      "Test Accuracy: 0.946\n",
      "Train F1: 0.689\n",
      "Test F1: 0.637\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.001\n",
      "Train Accuracy: 0.967\n",
      "Test Accuracy: 0.960\n",
      "Train F1: 0.753\n",
      "Test F1: 0.751\n",
      "\n",
      "Layer 2:\n",
      "Best C: 0.006\n",
      "Train Accuracy: 0.998\n",
      "Test Accuracy: 0.982\n",
      "Train F1: 0.981\n",
      "Test F1: 0.868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"action\"][\"Y_train\"], X_test, Ys_dict[\"action\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

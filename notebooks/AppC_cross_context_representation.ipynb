{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import configs\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from src.utils import find_ckpt_file, convert_to_tensor\n",
    "import h5py\n",
    "import random\n",
    "from src.evals.eval_trees import EvalTrees\n",
    "from src.evals.eval_trees import EvalCntrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=32-val_loss=0.000378.ckpt\n"
     ]
    }
   ],
   "source": [
    "corr = 0.0\n",
    "model_name, path_to_pkl, eval_dset_path = configs.get_model_paths(corr, \"tree_maze\")\n",
    "fignum = '10'\n",
    "recalc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=33-val_loss=0.000662.ckpt\n"
     ]
    }
   ],
   "source": [
    "corr = 0.25\n",
    "model_name, path_to_pkl, eval_dset_path = configs.get_model_paths(corr, \"tree_maze_bigger_models\", \"layer6\")\n",
    "fignum = '11'\n",
    "recalc_results = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parameters using regex\n",
    "import re\n",
    "\n",
    "n_embd = int(re.search(r'embd(\\d+)', model_name).group(1))\n",
    "n_layer = int(re.search(r'layer(\\d+)', model_name).group(1))\n",
    "n_head = int(re.search(r'head(\\d+)', model_name).group(1))\n",
    "dropout = float(re.search(r'drop(\\d*\\.?\\d*)', model_name).group(1))\n",
    "\n",
    "# Extract correlation and state_dim from eval dataset path\n",
    "state_dim = int(re.search(r'state_dim(\\d+)', eval_dset_path).group(1))\n",
    "\n",
    "model_config = {\n",
    "    \"n_embd\": n_embd,\n",
    "    \"n_layer\": n_layer,\n",
    "    \"n_head\": n_head,\n",
    "    \"state_dim\": 10,\n",
    "    \"action_dim\": 4,\n",
    "    \"dropout\": dropout,\n",
    "    \"test\": True,\n",
    "    \"name\": \"transformer_end_query\",\n",
    "    \"optimizer_config\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2430861/4170590101.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_to_pkl)\n"
     ]
    }
   ],
   "source": [
    "from src.models.transformer_end_query import Transformer\n",
    "model_config['initialization_seed'] = 0\n",
    "model = Transformer(**model_config)\n",
    "checkpoint = torch.load(path_to_pkl)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_envs = 150\n",
    "\n",
    "is_h5_file = eval_dset_path.endswith('.h5')\n",
    "if is_h5_file:\n",
    "    eval_trajs = h5py.File(eval_dset_path, 'r')\n",
    "    traj_indices = list(eval_trajs.keys())\n",
    "    n_eval_envs = min(n_eval_envs, len(traj_indices))\n",
    "    random.seed(0)\n",
    "    traj_indices = random.sample(traj_indices, n_eval_envs)\n",
    "    random.seed()\n",
    "    eval_trajs = [eval_trajs[i] for i in traj_indices]\n",
    "else:  # Pickle file\n",
    "    with open(eval_dset_path, 'rb') as f:\n",
    "        eval_trajs = pickle.load(f)\n",
    "    n_eval_envs = min(n_eval_envs, len(eval_trajs))\n",
    "    random.seed(0)\n",
    "    eval_trajs = random.sample(eval_trajs, n_eval_envs)\n",
    "    random.seed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(traj, model, state_features, seq_length, zero_reward=False):\n",
    "    hidden_states = [[] for _ in range(model.n_layer)]\n",
    "    \n",
    "    for state_feature in state_features: \n",
    "        batch = {\n",
    "            'context_states': convert_to_tensor([np.array(traj['context_states'])]),\n",
    "            'context_actions': convert_to_tensor([np.array(traj['context_actions'])]),\n",
    "            'context_next_states': convert_to_tensor([np.array(traj['context_next_states'])]),\n",
    "            'context_rewards': convert_to_tensor([np.array(traj['context_rewards'])[:, None]]),\n",
    "            'query_states': convert_to_tensor([np.array(state_feature)]),\n",
    "            }\n",
    "        batch['zeros'] = torch.zeros(1, 10 ** 2 + 4 + 1).float()\n",
    "        for k in batch.keys():\n",
    "            if 'context' in k:\n",
    "                batch[k] = batch[k][:,:seq_length]\n",
    "            batch[k] = batch[k].to(model.device)\n",
    "        model.save_activations = True\n",
    "        if zero_reward:\n",
    "            batch['context_rewards'] *= 0\n",
    "        with torch.no_grad():\n",
    "            out = model(batch)\n",
    "        _hidden_states = model.activations['hidden_states'][1:] # Tuple over layers\n",
    "        for i_layer in range(model.n_layer):\n",
    "            hidden_states[i_layer].append(\n",
    "                _hidden_states[i_layer].detach().cpu().numpy().squeeze()[-1])\n",
    "    return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_and_representation(traj, env, model):\n",
    "    nodes = []\n",
    "    hidden_states = []\n",
    "    seq_lengths = []\n",
    "    state_features = []\n",
    "    state_features = list(env.node_map.keys())\n",
    "\n",
    "    _nodes = [] \n",
    "    for state_feature in state_features:\n",
    "        _nodes.append(str(env.node_map[state_feature]))\n",
    "    for seq_length in [1, 25, 50, 75, 100, 250, 500, 750, 1000, 1100, 1200, 1300, 1400, 1500, 1600]:\n",
    "        _hidden_states = run_model(traj, model, state_features, seq_length=seq_length)\n",
    "        for l in range(model.n_layer):\n",
    "            if len(_hidden_states[l]) != len(_nodes):\n",
    "                print(l)\n",
    "                print(len(_hidden_states[l]), len(_nodes))\n",
    "                import pdb; pdb.set_trace()\n",
    "        nodes.append(_nodes)\n",
    "        hidden_states.append(_hidden_states)\n",
    "        seq_lengths.append(seq_length)\n",
    "\n",
    "    return nodes, hidden_states, seq_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recalc:\n",
    "    results = {\n",
    "        'nodes': [],\n",
    "        'hidden_states': [],\n",
    "        'model_layer': [], \n",
    "        'context_length': [],\n",
    "        'env': []\n",
    "    }\n",
    "    \n",
    "    for i_eval, traj in enumerate(eval_trajs[:10]):\n",
    "        env_config = {\n",
    "            'max_layers': 7,\n",
    "            'horizon': 1600,\n",
    "            'branching_prob': 1.0,\n",
    "            'node_encoding_corr': corr,\n",
    "            'state_dim': state_dim,\n",
    "            'initialization_seed': np.array(traj['initialization_seed']).item()\n",
    "        }\n",
    "        env = EvalCntrees().create_env(env_config, np.array(traj['goal']), i_eval)\n",
    "        nodes, hidden_states, context_lengths = get_node_and_representation(traj, env, model)\n",
    "        for _nodes, _hidden_states, _context_length in zip(nodes, hidden_states, context_lengths):\n",
    "            for i_layer, model_layer_hidden_states in enumerate(_hidden_states):\n",
    "                results['nodes'].extend(_nodes)\n",
    "                results['hidden_states'].extend(model_layer_hidden_states)\n",
    "                results['model_layer'].extend([i_layer] * len(_nodes))\n",
    "                results['context_length'].extend([_context_length] * len(_nodes))\n",
    "                results['env'].extend([i_eval] * len(_nodes))\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    same_node = {\n",
    "        'sim': [],\n",
    "        'model_layer': [],\n",
    "        'context_length': [],\n",
    "        'comparison_node_layer': []\n",
    "    }\n",
    "    diff_node = {\n",
    "        'sim': [],\n",
    "        'model_layer': [],\n",
    "        'context_length': [],\n",
    "        'comparison_node_layer': []\n",
    "    }\n",
    "    \n",
    "    for context_length in df['context_length'].unique():\n",
    "        context_length_df = df[df['context_length'] == context_length]\n",
    "        for i_layer in context_length_df['model_layer'].unique():\n",
    "            layer_df = context_length_df[context_length_df['model_layer'] == i_layer]\n",
    "            for node in layer_df['nodes'].unique():\n",
    "                node_df = layer_df[layer_df['nodes'] == node]\n",
    "                other_node_df = layer_df[layer_df['nodes'] != node]\n",
    "    \n",
    "                node_envs = node_df['env'].to_numpy()\n",
    "                other_node_envs = other_node_df['env'].to_numpy()\n",
    "                stacked_envs = np.concatenate((node_envs, other_node_envs))\n",
    "    \n",
    "                node_hidden_states = np.stack(node_df['hidden_states'].to_numpy())\n",
    "                other_node_hidden_states = np.stack(other_node_df['hidden_states'].to_numpy())\n",
    "    \n",
    "                n_same_node = node_hidden_states.shape[0]\n",
    "                stacked_reprs = np.vstack((node_hidden_states, other_node_hidden_states))\n",
    "                cc = np.corrcoef(stacked_reprs)\n",
    "                for i in range(n_same_node):\n",
    "                    for j in range(i+1, n_same_node):\n",
    "                        if stacked_envs[i] == stacked_envs[j]:\n",
    "                            continue\n",
    "                        same_node['sim'].append(cc[i, j])\n",
    "                        same_node['model_layer'].append(i_layer)\n",
    "                        same_node['context_length'].append(context_length)\n",
    "                        same_node['comparison_node_layer'].append(int(node[1]))\n",
    "                for i in range(n_same_node):\n",
    "                    for j in range(i+1, n_same_node):\n",
    "                        _j = j + n_same_node\n",
    "                        if stacked_envs[i] == stacked_envs[_j]:\n",
    "                            continue\n",
    "                        diff_node['sim'].append(cc[i, _j])\n",
    "                        diff_node['model_layer'].append(i_layer)\n",
    "                        diff_node['context_length'].append(context_length)\n",
    "                        diff_node['comparison_node_layer'].append(int(node[1]))\n",
    "    same_node_df = pd.DataFrame(same_node)\n",
    "    diff_node_df = pd.DataFrame(diff_node)\n",
    "    with open('pickles/AppC_fig{fignum}_cross_context_repr_summary.pkl', 'wb') as f:\n",
    "       pickle.dump({'same_node_df': same_node_df, 'diff_node_df': diff_node_df}, f)\n",
    "else:\n",
    "    with open('pickles/AppC_fig{fignum}_cross_context_repr_summary.pkl', 'rb') as f:\n",
    "       results = pickle.load(f)\n",
    "    same_node_df = results['same_node_df']\n",
    "    diff_node_df = results['diff_node_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 150x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_same_node_df = same_node_df[same_node_df['context_length'] == 1600]\n",
    "_diff_node_df = diff_node_df[diff_node_df['context_length'] == 1600]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.5, 1.5))\n",
    "ax = sns.barplot(\n",
    "    data=pd.concat([\n",
    "        _same_node_df.assign(type='Same Node'),\n",
    "        _diff_node_df.assign(type='Different Node')\n",
    "    ]),\n",
    "    x='comparison_node_layer', y='sim', hue='type', ax=ax, \n",
    "    legend=None\n",
    "    )\n",
    "\n",
    "for i, bar in enumerate(ax.patches):\n",
    "    if bar.get_facecolor() == (0.7642156862745098, 0.5318627450980391, 0.12598039215686285, 1):  # C1 color\n",
    "        bar.set_hatch('///')\n",
    "    bar.set_facecolor('dimgray')\n",
    "    \n",
    "# Set figure DPI higher for SVG export\n",
    "plt.rcParams['svg.fonttype'] = 'none'  # Ensure text remains as text in SVG\n",
    "plt.ylabel(r'Cross-Ctxt $\\rho$', fontsize=8)\n",
    "plt.xlabel('Maze Layer', fontsize=8)\n",
    "plt.xticks(np.arange(7), np.arange(7)+1, fontsize=6)\n",
    "plt.yticks([0, 0.25, 0.5], [0.0, '', 0.5], fontsize=6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figs_app/C_{fignum}C.png', transparent=True, dpi=300)\n",
    "plt.savefig(f'figs_app/C_{fignum}C.pdf', transparent=True, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

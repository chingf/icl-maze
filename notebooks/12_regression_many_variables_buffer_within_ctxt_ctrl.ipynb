{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import configs\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "from src.utils import find_ckpt_file, convert_to_tensor\n",
    "import h5py\n",
    "import random\n",
    "from src.evals.eval_trees import EvalTrees\n",
    "from src.evals.eval_trees import EvalCntrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = 0.25\n",
    "seq_length = 1200\n",
    "start_idx = 900  # where to start drawing tokens from, until seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=31-val_loss=0.000400.ckpt\n"
     ]
    }
   ],
   "source": [
    "engram_dir = \"/n/holylfs06/LABS/krajan_lab/Lab/cfang/icl-maze/\"\n",
    "wandb_project = \"tree_maze\"\n",
    "env_name = f\"cntree_layers7_bprob0.9_corr{corr}_state_dim10_envs300000_H800_explore\"\n",
    "if corr == 0.25:\n",
    "    model_name = \"transformer_end_query_embd512_layer3_head4_lr0.0001_drop0.2_initseed0_batch512\"\n",
    "elif corr == 0.:\n",
    "    model_name = \"transformer_end_query_embd512_layer3_head4_lr1e-05_drop0_initseed1_batch256\"\n",
    "else:\n",
    "    raise ValueError(f\"Unknown correlation value: {corr}\")\n",
    "model_path = os.path.join(engram_dir, wandb_project, env_name, \"models\", model_name)\n",
    "ckpt_name = find_ckpt_file(model_path, \"best\")\n",
    "print(ckpt_name)\n",
    "path_to_pkl = os.path.join(model_path, ckpt_name)\n",
    "\n",
    "eval_dset_path = f\"/n/holylfs06/LABS/krajan_lab/Lab/cfang/icl-maze/cntree/cntree_layers7_bprob1.0_corr{corr}_state_dim10_envs1000_H1600_explore/datasets/eval.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parameters using regex\n",
    "import re\n",
    "\n",
    "n_embd = int(re.search(r'embd(\\d+)', model_name).group(1))\n",
    "n_layer = int(re.search(r'layer(\\d+)', model_name).group(1))\n",
    "n_head = int(re.search(r'head(\\d+)', model_name).group(1))\n",
    "dropout = float(re.search(r'drop(\\d*\\.?\\d*)', model_name).group(1))\n",
    "\n",
    "# Extract correlation and state_dim from eval dataset path\n",
    "state_dim = int(re.search(r'state_dim(\\d+)', eval_dset_path).group(1))\n",
    "\n",
    "model_config = {\n",
    "    \"n_embd\": n_embd,\n",
    "    \"n_layer\": n_layer,\n",
    "    \"n_head\": n_head,\n",
    "    \"state_dim\": 10,\n",
    "    \"action_dim\": 4,\n",
    "    \"dropout\": dropout,\n",
    "    \"train_on_last_pred_only\": False,\n",
    "    \"test\": True,\n",
    "    \"name\": \"transformer_end_query\",\n",
    "    \"optimizer_config\": None,\n",
    "    \"linear_attention\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.transformer_end_query import Transformer\n",
    "model_config['initialization_seed'] = 0\n",
    "model = Transformer(**model_config)\n",
    "checkpoint = torch.load(path_to_pkl)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_envs = -1 #50\n",
    "\n",
    "is_h5_file = eval_dset_path.endswith('.h5')\n",
    "if is_h5_file:\n",
    "    eval_trajs = h5py.File(eval_dset_path, 'r')\n",
    "    traj_indices = list(eval_trajs.keys())\n",
    "    n_eval_envs = min(n_eval_envs, len(traj_indices))\n",
    "    random.seed(0)\n",
    "    traj_indices = random.sample(traj_indices, n_eval_envs)\n",
    "    random.seed()\n",
    "    if n_eval_envs != -1:\n",
    "        eval_trajs = [eval_trajs[i] for i in traj_indices]\n",
    "    else:\n",
    "        n_eval_envs = len(traj_indices)\n",
    "else:  # Pickle file\n",
    "    with open(eval_dset_path, 'rb') as f:\n",
    "        eval_trajs = pickle.load(f)\n",
    "    n_eval_envs = min(n_eval_envs, len(eval_trajs))\n",
    "    if n_eval_envs != -1:\n",
    "        random.seed(0)\n",
    "        eval_trajs = random.sample(eval_trajs, n_eval_envs)\n",
    "        random.seed()\n",
    "    else:\n",
    "        n_eval_envs = len(eval_trajs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(traj, model, seq_length=1200, start_idx=800):\n",
    "    hidden_states = []\n",
    "\n",
    "    batch = {\n",
    "        'context_states': convert_to_tensor([np.array(traj['context_states'])]),\n",
    "        'context_actions': convert_to_tensor([np.array(traj['context_actions'])]),\n",
    "        'context_next_states': convert_to_tensor([np.array(traj['context_next_states'])]),\n",
    "        'context_rewards': convert_to_tensor([np.array(traj['context_rewards'])[:, None]]),\n",
    "        'query_states': convert_to_tensor([np.array(traj['query_state'])]),  # Ignored\n",
    "        }\n",
    "    batch['zeros'] = torch.zeros(1, 10 ** 2 + 4 + 1).float()\n",
    "    for k in batch.keys():\n",
    "        if 'context' in k:\n",
    "            batch[k] = batch[k][:,:seq_length]\n",
    "        batch[k] = batch[k].to(model.device)\n",
    "    model.save_activations = True\n",
    "    with torch.no_grad():\n",
    "        out = model(batch)\n",
    "    _hidden_states = model.activations['hidden_states'][1:] # Tuple over layers of (1, seq, dim)\n",
    "    state_features = batch['context_states'][0][start_idx:].to('cpu').numpy()\n",
    "    next_state_features = batch['context_next_states'][0][start_idx:].to('cpu').numpy()\n",
    "    actions = batch['context_actions'][0].argmax(dim=1)[start_idx:].to('cpu').numpy()\n",
    "    for i_layer in range(model.n_layer):\n",
    "        hidden_states.append(_hidden_states[i_layer][0,start_idx:-1])\n",
    "    return hidden_states, state_features, next_state_features, actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Across context decoding\n",
    "(within-context is not that good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtree_location(layer, pos, subtree):\n",
    "    midpt = 2**(layer-1)\n",
    "    quarter_pt = midpt//2\n",
    "    eighth_pt = quarter_pt//2\n",
    "    if layer == 0:\n",
    "        return 0\n",
    "    if subtree == 'half':\n",
    "        return 1 if pos < midpt else 2\n",
    "    elif subtree == 'quarter':\n",
    "        if layer == 1:\n",
    "            return 0\n",
    "        bins = np.arange(0, 2**layer, quarter_pt)\n",
    "        return np.digitize([pos], bins)[0]\n",
    "    elif subtree == 'eighth':\n",
    "        if (layer == 1) or (layer == 2):\n",
    "            return 0\n",
    "        bins = np.arange(0, 2**layer, eighth_pt)\n",
    "        return np.digitize([pos], bins)[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_matrices():\n",
    "    X = [[] for _ in range(model.n_layer)]\n",
    "    Ys_dict = {\n",
    "        \"dist_from_goal\": [],\n",
    "        \"layer\": [],\n",
    "        \"node_identity\": [],\n",
    "        \"maze_half\": [],\n",
    "        \"maze_quarter\": [],\n",
    "        \"maze_eighth\": [],\n",
    "        'is_goal': [],\n",
    "        'same_half_as_goal': [],\n",
    "        'same_quarter_as_goal': [],\n",
    "        'opt_action': [],\n",
    "        'state_feature': [],\n",
    "        'next_state_feature': [],\n",
    "        \"on_path\": [],\n",
    "        \"on_lr_path\": [],\n",
    "    }\n",
    "    for i_eval in range(n_eval_envs):\n",
    "        onehot_env = np.zeros(n_eval_envs)\n",
    "        onehot_env[i_eval] = 1\n",
    "        traj = eval_trajs[i_eval]\n",
    "        first_reward = np.argwhere(np.array(traj['context_rewards'])>0)\n",
    "        if (first_reward.size == 0) or (first_reward[0] > start_idx):\n",
    "            continue\n",
    "\n",
    "        env_config = {\n",
    "            'max_layers': 7,\n",
    "            'horizon': 1600,\n",
    "            'branching_prob': 1.0,\n",
    "            'node_encoding_corr': corr,\n",
    "            'state_dim': state_dim,\n",
    "            'initialization_seed': np.array(traj['initialization_seed']).item()\n",
    "        }\n",
    "        env = EvalCntrees().create_env(env_config, np.array(traj['goal']), i_eval)\n",
    "        opt_action_map, dist_from_goal = env.make_opt_action_dict()\n",
    "\n",
    "\n",
    "        hidden_states, state_features, next_state_features, actions = run_model(traj, model, seq_length, start_idx)\n",
    "        goal_node = env.node_map[tuple(env.goal.tolist())]\n",
    "        goal_layer = goal_node.layer\n",
    "        goal_pos = goal_node.pos\n",
    "        seen_combos = set()\n",
    "        for state_idx, state_feature in enumerate(state_features):\n",
    "            next_state_feature = next_state_features[state_idx]\n",
    "            state_feature_tuple = tuple(state_feature.tolist())\n",
    "            combo = tuple(state_feature.tolist() + next_state_feature.tolist())\n",
    "            if combo in seen_combos:\n",
    "                continue\n",
    "            seen_combos.add(combo)\n",
    "            d = dist_from_goal[state_feature_tuple]\n",
    "            layer = env.node_map[state_feature_tuple].layer\n",
    "            pos = env.node_map[state_feature_tuple].pos\n",
    "            node_identity = 2**layer + pos\n",
    "            maze_half = get_subtree_location(layer, pos, 'half')\n",
    "            maze_quarter = get_subtree_location(layer, pos, 'quarter')\n",
    "            maze_eighth = get_subtree_location(layer, pos, 'eighth')\n",
    "            \n",
    "            Ys_dict[\"dist_from_goal\"].append(d)\n",
    "            Ys_dict[\"layer\"].append(layer)\n",
    "            Ys_dict[\"node_identity\"].append(node_identity)\n",
    "            Ys_dict[\"maze_half\"].append(maze_half)\n",
    "            Ys_dict[\"maze_quarter\"].append(maze_quarter)\n",
    "            Ys_dict[\"maze_eighth\"].append(maze_eighth)\n",
    "            Ys_dict[\"is_goal\"].append(state_feature_tuple == tuple(env.goal.tolist()))\n",
    "            Ys_dict[\"same_half_as_goal\"].append(maze_half == get_subtree_location(goal_layer, goal_pos, 'half'))\n",
    "            Ys_dict[\"same_quarter_as_goal\"].append(maze_quarter == get_subtree_location(goal_layer, goal_pos, 'quarter'))\n",
    "            Ys_dict[\"opt_action\"].append(opt_action_map[state_feature_tuple])\n",
    "            Ys_dict[\"state_feature\"].append(state_feature)\n",
    "            Ys_dict[\"next_state_feature\"].append(next_state_feature)\n",
    "            Ys_dict[\"on_path\"].append(actions[state_idx] == opt_action_map[state_feature_tuple])\n",
    "            Ys_dict[\"on_lr_path\"].append(\n",
    "                (actions[state_idx] == opt_action_map[state_feature_tuple]) and\n",
    "                (actions[state_idx] in [1, 2])\n",
    "                )\n",
    "\n",
    "            for layer in range(model.n_layer):\n",
    "                hidden_state = hidden_states[layer][state_idx].to('cpu').numpy()\n",
    "                X[layer].append(hidden_state)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    test_size = 0.1\n",
    "    test_start_idx = int(len(X[0])*(1-test_size))\n",
    "    all_indices = np.arange(len(X[0]))\n",
    "    np.random.shuffle(all_indices)\n",
    "    train_indices = all_indices[:test_start_idx]\n",
    "    test_indices = all_indices[test_start_idx:]\n",
    "\n",
    "    X_train = [[] for _ in range(model.n_layer)]\n",
    "    X_test = [[] for _ in range(model.n_layer)]\n",
    "    Ys_dict_train_test = {key: {'Y_train': [], 'Y_test': []} for key in Ys_dict}\n",
    "    # Use same indices for all layers to keep corresponding samples together\n",
    "    for layer, layer_data in enumerate(X):\n",
    "        X_train[layer] = [layer_data[i] for i in train_indices]\n",
    "        X_test[layer] = [layer_data[i] for i in test_indices]\n",
    "    for key in Ys_dict:\n",
    "        Ys_dict_train_test[key]['Y_train'] = [Ys_dict[key][i] for i in train_indices]\n",
    "        Ys_dict_train_test[key]['Y_test'] = [Ys_dict[key][i] for i in test_indices]\n",
    "    return X_train, X_test, Ys_dict_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def fit_and_evaluate_regression(X_train, Y_train, X_test, Y_test, print_scores=True):\n",
    "    from joblib import Parallel, delayed\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.linear_model import Ridge\n",
    "    \n",
    "    X_train_np = [np.array([_x for _x in x]) for x in X_train]\n",
    "    X_test_np = [np.array([_x for _x in x]) for x in X_test]\n",
    "    Y_train_np = np.array(Y_train)\n",
    "    Y_test_np = np.array(Y_test)\n",
    "\n",
    "    alphas = np.logspace(0, 4, 10)\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    def evaluate_fold(X, y, train_idx, val_idx, alpha):\n",
    "        # Train on this fold\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('ridge', Ridge(alpha=alpha))\n",
    "        ])\n",
    "        pipeline.fit(X[train_idx], y[train_idx])\n",
    "        # Get validation score\n",
    "        val_score = pipeline.score(X[val_idx], y[val_idx])\n",
    "        return val_score\n",
    "\n",
    "    pipelines = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for layer in range(len(X_train)-1):\n",
    "        # Parallel CV for each alpha\n",
    "        cv_scores = {alpha: [] for alpha in alphas}\n",
    "        for alpha in alphas:\n",
    "            scores = Parallel(n_jobs=-1)(\n",
    "                delayed(evaluate_fold)(\n",
    "                    X_train_np[layer], Y_train_np, \n",
    "                    train_idx, val_idx, alpha\n",
    "                )\n",
    "                for train_idx, val_idx in kf.split(X_train_np[layer])\n",
    "            )\n",
    "            cv_scores[alpha] = np.mean(scores)\n",
    "        \n",
    "        # Find best alpha\n",
    "        best_alpha = max(cv_scores.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Train final model with best alpha\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('ridge', Ridge(alpha=best_alpha))\n",
    "        ])\n",
    "        pipeline.fit(X_train_np[layer], Y_train_np)\n",
    "        \n",
    "        train_score = pipeline.score(X_train_np[layer], Y_train_np)\n",
    "        test_score = pipeline.score(X_test_np[layer], Y_test_np)\n",
    "        \n",
    "        pipelines.append(pipeline)\n",
    "        test_scores.append(test_score)\n",
    "        \n",
    "        if print_scores:\n",
    "            print(f\"Layer {layer}:\")\n",
    "            print(f\"Best alpha: {best_alpha:.3f}\")\n",
    "            print(f\"Train R2: {train_score:.3f}\")\n",
    "            print(f\"Test R2: {test_score:.3f}\")\n",
    "            print()\n",
    "            \n",
    "    return pipelines, test_scores\n",
    "\n",
    "def fit_and_evaluate_classification(X_train, Y_train, X_test, Y_test, print_scores=True):\n",
    "    import warnings\n",
    "    from sklearn.exceptions import ConvergenceWarning\n",
    "    warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    from joblib import Parallel, delayed\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "    X_train_np = [np.array([_x for _x in x]) for x in X_train]\n",
    "    X_test_np = [np.array([_x for _x in x]) for x in X_test]\n",
    "    Y_train_np = np.array(Y_train)\n",
    "    Y_test_np = np.array(Y_test)\n",
    "\n",
    "    Cs = np.logspace(-4, 4, 10)\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    def evaluate_fold(X, y, train_idx, val_idx, C):\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LogisticRegression(\n",
    "                C=C, \n",
    "                max_iter=3000,\n",
    "                class_weight='balanced',  # Add class weighting\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        pipeline.fit(X[train_idx], y[train_idx])\n",
    "        y_val_pred = pipeline.predict(X[val_idx])\n",
    "        # Use balanced accuracy score instead of regular accuracy\n",
    "        return balanced_accuracy_score(y[val_idx], y_val_pred)\n",
    "\n",
    "    pipelines = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for layer in range(len(X_train)-1):\n",
    "        # Parallel CV for each C value\n",
    "        cv_scores = {C: [] for C in Cs}\n",
    "        for C in Cs:\n",
    "            scores = Parallel(n_jobs=-1)(\n",
    "                delayed(evaluate_fold)(\n",
    "                    X_train_np[layer], Y_train_np, \n",
    "                    train_idx, val_idx, C\n",
    "                )\n",
    "                for train_idx, val_idx in kf.split(X_train_np[layer])\n",
    "            )\n",
    "            cv_scores[C] = np.mean(scores)\n",
    "        \n",
    "        # Find best C\n",
    "        best_C = max(cv_scores.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Train final model with best C\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LogisticRegression(\n",
    "                C=best_C, \n",
    "                max_iter=3000,\n",
    "                class_weight='balanced',  # Add class weighting\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        pipeline.fit(X_train_np[layer], Y_train_np)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(X_train_np[layer])\n",
    "        y_test_pred = pipeline.predict(X_test_np[layer])\n",
    "        \n",
    "        # Use balanced metrics\n",
    "        train_accuracy = balanced_accuracy_score(Y_train_np, y_train_pred)\n",
    "        test_accuracy = balanced_accuracy_score(Y_test_np, y_test_pred)\n",
    "        train_f1 = f1_score(Y_train_np, y_train_pred, average='weighted')\n",
    "        test_f1 = f1_score(Y_test_np, y_test_pred, average='weighted')\n",
    "\n",
    "        if print_scores:\n",
    "            print(f\"Layer {layer}:\")\n",
    "            print(f\"Best C: {best_C:.3f}\")\n",
    "            print(f\"Train Balanced Accuracy: {train_accuracy:.3f}\")\n",
    "            print(f\"Test Balanced Accuracy: {test_accuracy:.3f}\")\n",
    "            print(f\"Train Weighted F1: {train_f1:.3f}\")\n",
    "            print(f\"Test Weighted F1: {test_f1:.3f}\")\n",
    "            # Add class distribution information\n",
    "            print(\"Class distribution:\")\n",
    "            for cls in np.unique(Y_train_np):\n",
    "                print(f\"Class {cls}: {np.sum(Y_train_np == cls)} samples\")\n",
    "            print()\n",
    "\n",
    "    return pipelines, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Ys_dict = make_train_test_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.359\n",
      "Train Balanced Accuracy: 0.758\n",
      "Test Balanced Accuracy: 0.746\n",
      "Train Weighted F1: 0.767\n",
      "Test Weighted F1: 0.762\n",
      "Class distribution:\n",
      "Class False: 5545 samples\n",
      "Class True: 1959 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.359\n",
      "Train Balanced Accuracy: 0.814\n",
      "Test Balanced Accuracy: 0.813\n",
      "Train Weighted F1: 0.816\n",
      "Test Weighted F1: 0.806\n",
      "Class distribution:\n",
      "Class False: 5545 samples\n",
      "Class True: 1959 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"same_quarter_as_goal\"][\"Y_train\"], X_test, Ys_dict[\"same_quarter_as_goal\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.046\n",
      "Train Balanced Accuracy: 0.711\n",
      "Test Balanced Accuracy: 0.669\n",
      "Train Weighted F1: 0.711\n",
      "Test Weighted F1: 0.671\n",
      "Class distribution:\n",
      "Class False: 3781 samples\n",
      "Class True: 3723 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.359\n",
      "Train Balanced Accuracy: 0.778\n",
      "Test Balanced Accuracy: 0.760\n",
      "Train Weighted F1: 0.778\n",
      "Test Weighted F1: 0.760\n",
      "Class distribution:\n",
      "Class False: 3781 samples\n",
      "Class True: 3723 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"same_half_as_goal\"][\"Y_train\"], X_test, Ys_dict[\"same_half_as_goal\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.046\n",
      "Train Balanced Accuracy: 0.867\n",
      "Test Balanced Accuracy: 0.805\n",
      "Train Weighted F1: 0.894\n",
      "Test Weighted F1: 0.880\n",
      "Class distribution:\n",
      "Class False: 7030 samples\n",
      "Class True: 474 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.046\n",
      "Train Balanced Accuracy: 0.946\n",
      "Test Balanced Accuracy: 0.878\n",
      "Train Weighted F1: 0.949\n",
      "Test Weighted F1: 0.938\n",
      "Class distribution:\n",
      "Class False: 7030 samples\n",
      "Class True: 474 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(\n",
    "    X_train,\n",
    "    [y <= 3 for y in Ys_dict[\"dist_from_goal\"][\"Y_train\"]],\n",
    "    X_test,\n",
    "    [y <= 3 for y in Ys_dict[\"dist_from_goal\"][\"Y_test\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.359\n",
      "Train Balanced Accuracy: 0.976\n",
      "Test Balanced Accuracy: 0.964\n",
      "Train Weighted F1: 0.973\n",
      "Test Weighted F1: 0.964\n",
      "Class distribution:\n",
      "Class False: 5210 samples\n",
      "Class True: 2294 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.359\n",
      "Train Balanced Accuracy: 0.977\n",
      "Test Balanced Accuracy: 0.967\n",
      "Train Weighted F1: 0.975\n",
      "Test Weighted F1: 0.969\n",
      "Class distribution:\n",
      "Class False: 5210 samples\n",
      "Class True: 2294 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(\n",
    "    X_train,\n",
    "    [y == 6 for y in Ys_dict[\"layer\"][\"Y_train\"]],\n",
    "    X_test,\n",
    "    [y == 6 for y in Ys_dict[\"layer\"][\"Y_test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best alpha: 166.810\n",
      "Train R2: 0.528\n",
      "Test R2: 0.529\n",
      "\n",
      "Layer 1:\n",
      "Best alpha: 59.948\n",
      "Train R2: 0.771\n",
      "Test R2: 0.772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_regression(X_train, Ys_dict[\"layer\"][\"Y_train\"], X_test, Ys_dict[\"layer\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"node_identity\"][\"Y_train\"], X_test, Ys_dict[\"node_identity\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.359\n",
      "Train Balanced Accuracy: 0.920\n",
      "Test Balanced Accuracy: 0.884\n",
      "Train Weighted F1: 0.881\n",
      "Test Weighted F1: 0.855\n",
      "Class distribution:\n",
      "Class 0: 149 samples\n",
      "Class 1: 9033 samples\n",
      "Class 2: 8908 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.359\n",
      "Train Balanced Accuracy: 0.929\n",
      "Test Balanced Accuracy: 0.895\n",
      "Train Weighted F1: 0.894\n",
      "Test Weighted F1: 0.872\n",
      "Class distribution:\n",
      "Class 0: 149 samples\n",
      "Class 1: 9033 samples\n",
      "Class 2: 8908 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"maze_half\"][\"Y_train\"], X_test, Ys_dict[\"maze_half\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import configs\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "from src.utils import find_ckpt_file, convert_to_tensor\n",
    "import h5py\n",
    "import random\n",
    "from src.evals.eval_trees import EvalTrees\n",
    "from src.evals.eval_trees import EvalCntrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = 0.25\n",
    "seq_length = 1200\n",
    "start_idx = 900  # where to start drawing tokens from, until seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=31-val_loss=0.000400.ckpt\n"
     ]
    }
   ],
   "source": [
    "engram_dir = \"/n/holylfs06/LABS/krajan_lab/Lab/cfang/icl-maze/\"\n",
    "wandb_project = \"tree_maze\"\n",
    "env_name = f\"cntree_layers7_bprob0.9_corr{corr}_state_dim10_envs300000_H800_explore\"\n",
    "if corr == 0.25:\n",
    "    model_name = \"transformer_end_query_embd512_layer3_head4_lr0.0001_drop0.2_initseed0_batch512\"\n",
    "elif corr == 0.:\n",
    "    model_name = \"transformer_end_query_embd512_layer3_head4_lr1e-05_drop0_initseed1_batch256\"\n",
    "else:\n",
    "    raise ValueError(f\"Unknown correlation value: {corr}\")\n",
    "model_path = os.path.join(engram_dir, wandb_project, env_name, \"models\", model_name)\n",
    "ckpt_name = find_ckpt_file(model_path, \"best\")\n",
    "print(ckpt_name)\n",
    "path_to_pkl = os.path.join(model_path, ckpt_name)\n",
    "\n",
    "eval_dset_path = f\"/n/holylfs06/LABS/krajan_lab/Lab/cfang/icl-maze/cntree/cntree_layers7_bprob1.0_corr{corr}_state_dim10_envs1000_H1600_explore/datasets/eval.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parameters using regex\n",
    "import re\n",
    "\n",
    "n_embd = int(re.search(r'embd(\\d+)', model_name).group(1))\n",
    "n_layer = int(re.search(r'layer(\\d+)', model_name).group(1))\n",
    "n_head = int(re.search(r'head(\\d+)', model_name).group(1))\n",
    "dropout = float(re.search(r'drop(\\d*\\.?\\d*)', model_name).group(1))\n",
    "\n",
    "# Extract correlation and state_dim from eval dataset path\n",
    "state_dim = int(re.search(r'state_dim(\\d+)', eval_dset_path).group(1))\n",
    "\n",
    "model_config = {\n",
    "    \"n_embd\": n_embd,\n",
    "    \"n_layer\": n_layer,\n",
    "    \"n_head\": n_head,\n",
    "    \"state_dim\": 10,\n",
    "    \"action_dim\": 4,\n",
    "    \"dropout\": dropout,\n",
    "    \"train_on_last_pred_only\": False,\n",
    "    \"test\": True,\n",
    "    \"name\": \"transformer_end_query\",\n",
    "    \"optimizer_config\": None,\n",
    "    \"linear_attention\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.transformer_end_query import Transformer\n",
    "model_config['initialization_seed'] = 0\n",
    "model = Transformer(**model_config)\n",
    "checkpoint = torch.load(path_to_pkl)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_envs = -1 #50\n",
    "\n",
    "is_h5_file = eval_dset_path.endswith('.h5')\n",
    "if is_h5_file:\n",
    "    eval_trajs = h5py.File(eval_dset_path, 'r')\n",
    "    traj_indices = list(eval_trajs.keys())\n",
    "    n_eval_envs = min(n_eval_envs, len(traj_indices))\n",
    "    random.seed(0)\n",
    "    traj_indices = random.sample(traj_indices, n_eval_envs)\n",
    "    random.seed()\n",
    "    if n_eval_envs != -1:\n",
    "        eval_trajs = [eval_trajs[i] for i in traj_indices]\n",
    "    else:\n",
    "        n_eval_envs = len(traj_indices)\n",
    "else:  # Pickle file\n",
    "    with open(eval_dset_path, 'rb') as f:\n",
    "        eval_trajs = pickle.load(f)\n",
    "    n_eval_envs = min(n_eval_envs, len(eval_trajs))\n",
    "    if n_eval_envs != -1:\n",
    "        random.seed(0)\n",
    "        eval_trajs = random.sample(eval_trajs, n_eval_envs)\n",
    "        random.seed()\n",
    "    else:\n",
    "        n_eval_envs = len(eval_trajs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(traj, model, seq_length=1200, start_idx=800):\n",
    "    hidden_states = []\n",
    "\n",
    "    batch = {\n",
    "        'context_states': convert_to_tensor([np.array(traj['context_states'])]),\n",
    "        'context_actions': convert_to_tensor([np.array(traj['context_actions'])]),\n",
    "        'context_next_states': convert_to_tensor([np.array(traj['context_next_states'])]),\n",
    "        'context_rewards': convert_to_tensor([np.array(traj['context_rewards'])[:, None]]),\n",
    "        'query_states': convert_to_tensor([np.array(traj['query_state'])]),  # Ignored\n",
    "        }\n",
    "    batch['zeros'] = torch.zeros(1, 10 ** 2 + 4 + 1).float()\n",
    "    for k in batch.keys():\n",
    "        if 'context' in k:\n",
    "            batch[k] = batch[k][:,:seq_length]\n",
    "        batch[k] = batch[k].to(model.device)\n",
    "    model.save_activations = True\n",
    "    with torch.no_grad():\n",
    "        out = model(batch)\n",
    "    _hidden_states = model.activations['hidden_states'][1:] # Tuple over layers of (1, seq, dim)\n",
    "    state_features = batch['context_states'][0][start_idx:].to('cpu').numpy()\n",
    "    next_state_features = batch['context_next_states'][0][start_idx:].to('cpu').numpy()\n",
    "    actions = batch['context_actions'][0].argmax(dim=1)[start_idx:].to('cpu').numpy()\n",
    "    for i_layer in range(model.n_layer):\n",
    "        hidden_states.append(_hidden_states[i_layer][0,start_idx:-1])\n",
    "    return hidden_states, state_features, next_state_features, actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Across context decoding\n",
    "(within-context is not that good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtree_location(layer, pos, subtree):\n",
    "    midpt = 2**(layer-1)\n",
    "    quarter_pt = midpt//2\n",
    "    eighth_pt = quarter_pt//2\n",
    "    if layer == 0:\n",
    "        return 0\n",
    "    if subtree == 'half':\n",
    "        return 1 if pos < midpt else 2\n",
    "    elif subtree == 'quarter':\n",
    "        if layer == 1:\n",
    "            return 0\n",
    "        bins = np.arange(0, 2**layer, quarter_pt)\n",
    "        return np.digitize([pos], bins)[0]\n",
    "    elif subtree == 'eighth':\n",
    "        if (layer == 1) or (layer == 2):\n",
    "            return 0\n",
    "        bins = np.arange(0, 2**layer, eighth_pt)\n",
    "        return np.digitize([pos], bins)[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_envs = np.arange(1, int(n_eval_envs*0.9))\n",
    "test_envs = np.arange(int(n_eval_envs*0.9), n_eval_envs)\n",
    "\n",
    "def make_train_test_matrices():\n",
    "    X_train = [[] for _ in range(model.n_layer)]\n",
    "    X_test = [[] for _ in range(model.n_layer)]\n",
    "    Ys_dict = {\n",
    "        \"dist_from_goal\": {\"Y_train\": [], \"Y_test\": []},\n",
    "        \"layer\": {\"Y_train\": [], \"Y_test\": []},\n",
    "        \"node_identity\": {\"Y_train\": [], \"Y_test\": []},\n",
    "        \"maze_half\": {\"Y_train\": [], \"Y_test\": []},\n",
    "        \"maze_quarter\": {\"Y_train\": [], \"Y_test\": []},\n",
    "        \"maze_eighth\": {\"Y_train\": [], \"Y_test\": []},\n",
    "        'is_goal': {\"Y_train\": [], \"Y_test\": []},\n",
    "        'same_half_as_goal': {\"Y_train\": [], \"Y_test\": []},\n",
    "        'opt_action': {\"Y_train\": [], \"Y_test\": []},\n",
    "        'state_feature': {\"Y_train\": [], \"Y_test\": []},\n",
    "        'next_state_feature': {\"Y_train\": [], \"Y_test\": []},\n",
    "        \"on_path\": {\"Y_train\": [], \"Y_test\": []},\n",
    "        \"on_lr_path\": {\"Y_train\": [], \"Y_test\": []},\n",
    "    }\n",
    "    for i_eval in range(n_eval_envs):\n",
    "        traj = eval_trajs[i_eval]\n",
    "        first_reward = np.argwhere(np.array(traj['context_rewards'])>0)\n",
    "        if (first_reward.size == 0) or (first_reward[0] > start_idx):\n",
    "            continue\n",
    "\n",
    "        env_config = {\n",
    "            'max_layers': 7,\n",
    "            'horizon': 1600,\n",
    "            'branching_prob': 1.0,\n",
    "            'node_encoding_corr': corr,\n",
    "            'state_dim': state_dim,\n",
    "            'initialization_seed': np.array(traj['initialization_seed']).item()\n",
    "        }\n",
    "        env = EvalCntrees().create_env(env_config, np.array(traj['goal']), i_eval)\n",
    "        opt_action_map, dist_from_goal = env.make_opt_action_dict()\n",
    "\n",
    "\n",
    "        hidden_states, state_features, next_state_features, actions = run_model(traj, model, seq_length, start_idx)\n",
    "        goal_node = env.node_map[tuple(env.goal.tolist())]\n",
    "        goal_layer = goal_node.layer\n",
    "        goal_pos = goal_node.pos\n",
    "        for state_idx, state_feature in enumerate(state_features):\n",
    "            next_state_feature = next_state_features[state_idx]\n",
    "            state_feature_tuple = tuple(state_feature.tolist())\n",
    "            d = dist_from_goal[state_feature_tuple]\n",
    "            layer = env.node_map[state_feature_tuple].layer\n",
    "            pos = env.node_map[state_feature_tuple].pos\n",
    "            node_identity = 2**layer + pos\n",
    "            maze_half = get_subtree_location(layer, pos, 'half')\n",
    "            maze_quarter = get_subtree_location(layer, pos, 'quarter')\n",
    "            maze_eighth = get_subtree_location(layer, pos, 'eighth')\n",
    "            \n",
    "            Y_key = \"Y_train\" if i_eval in train_envs else \"Y_test\"\n",
    "            Ys_dict[\"dist_from_goal\"][Y_key].append(d)\n",
    "            Ys_dict[\"layer\"][Y_key].append(layer)\n",
    "            Ys_dict[\"node_identity\"][Y_key].append(node_identity)\n",
    "            Ys_dict[\"maze_half\"][Y_key].append(maze_half)\n",
    "            Ys_dict[\"maze_quarter\"][Y_key].append(maze_quarter)\n",
    "            Ys_dict[\"maze_eighth\"][Y_key].append(maze_eighth)\n",
    "            Ys_dict[\"is_goal\"][Y_key].append(state_feature_tuple == tuple(env.goal.tolist()))\n",
    "            Ys_dict[\"same_half_as_goal\"][Y_key].append(maze_half == get_subtree_location(goal_layer, goal_pos, 'half'))\n",
    "            Ys_dict[\"opt_action\"][Y_key].append(opt_action_map[state_feature_tuple])\n",
    "            Ys_dict[\"state_feature\"][Y_key].append(state_feature)\n",
    "            Ys_dict[\"next_state_feature\"][Y_key].append(next_state_feature)\n",
    "            Ys_dict[\"on_path\"][Y_key].append(actions[state_idx] == opt_action_map[state_feature_tuple])\n",
    "            Ys_dict[\"on_lr_path\"][Y_key].append(\n",
    "                (actions[state_idx] == opt_action_map[state_feature_tuple]) and\n",
    "                (actions[state_idx] in [1, 2])\n",
    "                )\n",
    "\n",
    "            for layer in range(model.n_layer):\n",
    "                hidden_state = hidden_states[layer][state_idx]\n",
    "                if i_eval in train_envs:\n",
    "                    X_train[layer].append(hidden_state.to('cpu').numpy())\n",
    "                else:\n",
    "                    X_test[layer].append(hidden_state.to('cpu').numpy())\n",
    "        torch.cuda.empty_cache()\n",
    "    return X_train, X_test, Ys_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def fit_and_evaluate_regression(X_train, Y_train, X_test, Y_test, print_scores=True):\n",
    "    from joblib import Parallel, delayed\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.linear_model import Ridge\n",
    "    \n",
    "    X_train_np = [np.array([_x for _x in x]) for x in X_train]\n",
    "    X_test_np = [np.array([_x for _x in x]) for x in X_test]\n",
    "    Y_train_np = np.array(Y_train)\n",
    "    Y_test_np = np.array(Y_test)\n",
    "\n",
    "    alphas = np.logspace(0, 4, 10)\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    def evaluate_fold(X, y, train_idx, val_idx, alpha):\n",
    "        # Train on this fold\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('ridge', Ridge(alpha=alpha))\n",
    "        ])\n",
    "        pipeline.fit(X[train_idx], y[train_idx])\n",
    "        # Get validation score\n",
    "        val_score = pipeline.score(X[val_idx], y[val_idx])\n",
    "        return val_score\n",
    "\n",
    "    pipelines = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for layer in range(len(X_train)-1):\n",
    "        # Parallel CV for each alpha\n",
    "        cv_scores = {alpha: [] for alpha in alphas}\n",
    "        for alpha in alphas:\n",
    "            scores = Parallel(n_jobs=-1)(\n",
    "                delayed(evaluate_fold)(\n",
    "                    X_train_np[layer], Y_train_np, \n",
    "                    train_idx, val_idx, alpha\n",
    "                )\n",
    "                for train_idx, val_idx in kf.split(X_train_np[layer])\n",
    "            )\n",
    "            cv_scores[alpha] = np.mean(scores)\n",
    "        \n",
    "        # Find best alpha\n",
    "        best_alpha = max(cv_scores.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Train final model with best alpha\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('ridge', Ridge(alpha=best_alpha))\n",
    "        ])\n",
    "        pipeline.fit(X_train_np[layer], Y_train_np)\n",
    "        \n",
    "        train_score = pipeline.score(X_train_np[layer], Y_train_np)\n",
    "        test_score = pipeline.score(X_test_np[layer], Y_test_np)\n",
    "        \n",
    "        pipelines.append(pipeline)\n",
    "        test_scores.append(test_score)\n",
    "        \n",
    "        if print_scores:\n",
    "            print(f\"Layer {layer}:\")\n",
    "            print(f\"Best alpha: {best_alpha:.3f}\")\n",
    "            print(f\"Train R2: {train_score:.3f}\")\n",
    "            print(f\"Test R2: {test_score:.3f}\")\n",
    "            print()\n",
    "            \n",
    "    return pipelines, test_scores\n",
    "\n",
    "def fit_and_evaluate_classification(X_train, Y_train, X_test, Y_test, print_scores=True):\n",
    "    import warnings\n",
    "    from sklearn.exceptions import ConvergenceWarning\n",
    "    warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    from joblib import Parallel, delayed\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "    X_train_np = [np.array([_x for _x in x]) for x in X_train]\n",
    "    X_test_np = [np.array([_x for _x in x]) for x in X_test]\n",
    "    Y_train_np = np.array(Y_train)\n",
    "    Y_test_np = np.array(Y_test)\n",
    "\n",
    "    Cs = np.logspace(-4, 4, 10)\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    def evaluate_fold(X, y, train_idx, val_idx, C):\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LogisticRegression(\n",
    "                C=C, \n",
    "                max_iter=3000,\n",
    "                class_weight='balanced',  # Add class weighting\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        pipeline.fit(X[train_idx], y[train_idx])\n",
    "        y_val_pred = pipeline.predict(X[val_idx])\n",
    "        # Use balanced accuracy score instead of regular accuracy\n",
    "        return balanced_accuracy_score(y[val_idx], y_val_pred)\n",
    "\n",
    "    pipelines = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for layer in range(len(X_train)-1):\n",
    "        # Parallel CV for each C value\n",
    "        cv_scores = {C: [] for C in Cs}\n",
    "        for C in Cs:\n",
    "            scores = Parallel(n_jobs=-1)(\n",
    "                delayed(evaluate_fold)(\n",
    "                    X_train_np[layer], Y_train_np, \n",
    "                    train_idx, val_idx, C\n",
    "                )\n",
    "                for train_idx, val_idx in kf.split(X_train_np[layer])\n",
    "            )\n",
    "            cv_scores[C] = np.mean(scores)\n",
    "        \n",
    "        # Find best C\n",
    "        best_C = max(cv_scores.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Train final model with best C\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LogisticRegression(\n",
    "                C=best_C, \n",
    "                max_iter=3000,\n",
    "                class_weight='balanced',  # Add class weighting\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        pipeline.fit(X_train_np[layer], Y_train_np)\n",
    "        \n",
    "        y_train_pred = pipeline.predict(X_train_np[layer])\n",
    "        y_test_pred = pipeline.predict(X_test_np[layer])\n",
    "        \n",
    "        # Use balanced metrics\n",
    "        train_accuracy = balanced_accuracy_score(Y_train_np, y_train_pred)\n",
    "        test_accuracy = balanced_accuracy_score(Y_test_np, y_test_pred)\n",
    "        train_f1 = f1_score(Y_train_np, y_train_pred, average='weighted')\n",
    "        test_f1 = f1_score(Y_test_np, y_test_pred, average='weighted')\n",
    "\n",
    "        if print_scores:\n",
    "            print(f\"Layer {layer}:\")\n",
    "            print(f\"Best C: {best_C:.3f}\")\n",
    "            print(f\"Train Balanced Accuracy: {train_accuracy:.3f}\")\n",
    "            print(f\"Test Balanced Accuracy: {test_accuracy:.3f}\")\n",
    "            print(f\"Train Weighted F1: {train_f1:.3f}\")\n",
    "            print(f\"Test Weighted F1: {test_f1:.3f}\")\n",
    "            # Add class distribution information\n",
    "            print(\"Class distribution:\")\n",
    "            for cls in np.unique(Y_train_np):\n",
    "                print(f\"Class {cls}: {np.sum(Y_train_np == cls)} samples\")\n",
    "            print()\n",
    "\n",
    "    return pipelines, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Ys_dict = make_train_test_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.046\n",
      "Train Balanced Accuracy: 0.960\n",
      "Test Balanced Accuracy: 0.681\n",
      "Train Weighted F1: 0.947\n",
      "Test Weighted F1: 0.932\n",
      "Class distribution:\n",
      "Class False: 18000 samples\n",
      "Class True: 300 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.006\n",
      "Train Balanced Accuracy: 0.973\n",
      "Test Balanced Accuracy: 0.879\n",
      "Train Weighted F1: 0.964\n",
      "Test Weighted F1: 0.956\n",
      "Class distribution:\n",
      "Class False: 18000 samples\n",
      "Class True: 300 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"on_lr_path\"][\"Y_train\"], X_test, Ys_dict[\"on_lr_path\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.359\n",
      "Train Balanced Accuracy: 0.978\n",
      "Test Balanced Accuracy: 0.957\n",
      "Train Weighted F1: 0.980\n",
      "Test Weighted F1: 0.961\n",
      "Class distribution:\n",
      "Class False: 18555 samples\n",
      "Class True: 8245 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 2.783\n",
      "Train Balanced Accuracy: 0.986\n",
      "Test Balanced Accuracy: 0.956\n",
      "Train Weighted F1: 0.986\n",
      "Test Weighted F1: 0.962\n",
      "Class distribution:\n",
      "Class False: 18555 samples\n",
      "Class True: 8245 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"on_path\"][\"Y_train\"], X_test, Ys_dict[\"on_path\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 21.544\n",
      "Train Balanced Accuracy: 0.957\n",
      "Test Balanced Accuracy: 0.638\n",
      "Train Weighted F1: 0.905\n",
      "Test Weighted F1: 0.839\n",
      "Class distribution:\n",
      "Class 0: 25072 samples\n",
      "Class 1: 682 samples\n",
      "Class 2: 803 samples\n",
      "Class 3: 243 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 2.783\n",
      "Train Balanced Accuracy: 0.988\n",
      "Test Balanced Accuracy: 0.682\n",
      "Train Weighted F1: 0.960\n",
      "Test Weighted F1: 0.901\n",
      "Class distribution:\n",
      "Class 0: 25072 samples\n",
      "Class 1: 682 samples\n",
      "Class 2: 803 samples\n",
      "Class 3: 243 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"opt_action\"][\"Y_train\"], X_test, Ys_dict[\"opt_action\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.046\n",
      "Train Balanced Accuracy: 1.000\n",
      "Test Balanced Accuracy: 1.000\n",
      "Train Weighted F1: 1.000\n",
      "Test Weighted F1: 1.000\n",
      "Class distribution:\n",
      "Class False: 26557 samples\n",
      "Class True: 243 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.046\n",
      "Train Balanced Accuracy: 1.000\n",
      "Test Balanced Accuracy: 1.000\n",
      "Train Weighted F1: 1.000\n",
      "Test Weighted F1: 1.000\n",
      "Class distribution:\n",
      "Class False: 26557 samples\n",
      "Class True: 243 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"is_goal\"][\"Y_train\"], X_test, Ys_dict[\"is_goal\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 10000.000\n",
      "Train Balanced Accuracy: 0.744\n",
      "Test Balanced Accuracy: 0.556\n",
      "Train Weighted F1: 0.744\n",
      "Test Weighted F1: 0.591\n",
      "Class distribution:\n",
      "Class False: 13375 samples\n",
      "Class True: 13425 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 21.544\n",
      "Train Balanced Accuracy: 0.809\n",
      "Test Balanced Accuracy: 0.549\n",
      "Train Weighted F1: 0.809\n",
      "Test Weighted F1: 0.596\n",
      "Class distribution:\n",
      "Class False: 13375 samples\n",
      "Class True: 13425 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"same_half_as_goal\"][\"Y_train\"], X_test, Ys_dict[\"same_half_as_goal\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 2.783\n",
      "Train Balanced Accuracy: 0.950\n",
      "Test Balanced Accuracy: 0.737\n",
      "Train Weighted F1: 0.943\n",
      "Test Weighted F1: 0.857\n",
      "Class distribution:\n",
      "Class False: 17212 samples\n",
      "Class True: 1088 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 2.783\n",
      "Train Balanced Accuracy: 0.985\n",
      "Test Balanced Accuracy: 0.858\n",
      "Train Weighted F1: 0.978\n",
      "Test Weighted F1: 0.922\n",
      "Class distribution:\n",
      "Class False: 17212 samples\n",
      "Class True: 1088 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(\n",
    "    X_train,\n",
    "    [y <= 3 for y in Ys_dict[\"dist_from_goal\"][\"Y_train\"]],\n",
    "    X_test,\n",
    "    [y <= 3 for y in Ys_dict[\"dist_from_goal\"][\"Y_test\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 1291.550\n",
      "Train Balanced Accuracy: 0.913\n",
      "Test Balanced Accuracy: 0.865\n",
      "Train Weighted F1: 0.912\n",
      "Test Weighted F1: 0.865\n",
      "Class distribution:\n",
      "Class False: 14821 samples\n",
      "Class True: 11979 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 2.783\n",
      "Train Balanced Accuracy: 0.983\n",
      "Test Balanced Accuracy: 0.958\n",
      "Train Weighted F1: 0.983\n",
      "Test Weighted F1: 0.960\n",
      "Class distribution:\n",
      "Class False: 14821 samples\n",
      "Class True: 11979 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(\n",
    "    X_train,\n",
    "    [y == 6 for y in Ys_dict[\"layer\"][\"Y_train\"]],\n",
    "    X_test,\n",
    "    [y == 6 for y in Ys_dict[\"layer\"][\"Y_test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best alpha: 21.544\n",
      "Train R2: 0.645\n",
      "Test R2: 0.549\n",
      "\n",
      "Layer 1:\n",
      "Best alpha: 21.544\n",
      "Train R2: 0.845\n",
      "Test R2: 0.743\n",
      "\n",
      "Layer 2:\n",
      "Best alpha: 21.544\n",
      "Train R2: 0.866\n",
      "Test R2: 0.763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_regression(X_train, Ys_dict[\"layer\"][\"Y_train\"], X_test, Ys_dict[\"layer\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"node_identity\"][\"Y_train\"], X_test, Ys_dict[\"node_identity\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Best C: 0.359\n",
      "Train Balanced Accuracy: 0.816\n",
      "Test Balanced Accuracy: 0.399\n",
      "Train Weighted F1: 0.730\n",
      "Test Weighted F1: 0.453\n",
      "Class distribution:\n",
      "Class 0: 227 samples\n",
      "Class 1: 14722 samples\n",
      "Class 2: 11851 samples\n",
      "\n",
      "Layer 1:\n",
      "Best C: 0.046\n",
      "Train Balanced Accuracy: 0.858\n",
      "Test Balanced Accuracy: 0.463\n",
      "Train Weighted F1: 0.790\n",
      "Test Weighted F1: 0.461\n",
      "Class distribution:\n",
      "Class 0: 227 samples\n",
      "Class 1: 14722 samples\n",
      "Class 2: 11851 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"maze_half\"][\"Y_train\"], X_test, Ys_dict[\"maze_half\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"maze_quarter\"][\"Y_train\"], X_test, Ys_dict[\"maze_quarter\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"maze_eighth\"][\"Y_train\"], X_test, Ys_dict[\"maze_eighth\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline, test_score = fit_and_evaluate_classification(X_train, Ys_dict[\"action\"][\"Y_train\"], X_test, Ys_dict[\"action\"][\"Y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
